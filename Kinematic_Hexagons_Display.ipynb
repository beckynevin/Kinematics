{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled\n"
     ]
    }
   ],
   "source": [
    "import pyfits\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "import matplotlib\n",
    "import math\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion\n",
    "from scipy.ndimage import iterate_structure\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "import scipy.optimize as opt\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from astropy.convolution import convolve\n",
    "from astropy.io import fits\n",
    "import math\n",
    "import photutils\n",
    "import statmorph\n",
    "from skimage import measure\n",
    "from bresenham import bresenham\n",
    "from photutils import CircularAperture,aperture_photometry\n",
    "import cv2\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import asarray as ar,exp\n",
    "\n",
    "\n",
    "\n",
    "print('compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gauss(x,a,x0,sigma,offset):\n",
    "    return a*exp(-(x-x0)**2/(2*sigma**2))+offset\n",
    "            \n",
    "def fit_2_gaussian(data):\n",
    "    \"\"\"\n",
    "    Fits 2D gaussians to surface brightness using the guesses from the low pass filter of the galaxy locations\n",
    "    Basically, this is my own design of a rough precursor to Source Extractor\n",
    "    \"\"\"\n",
    "    # Create x and y indices\n",
    "    data=np.flipud(data)\n",
    "    x = np.linspace(0, np.shape(data)[0]-1,np.shape(data)[0])\n",
    "    y = np.linspace(0, np.shape(data)[1]-1, np.shape(data)[1])\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.hold(True)\n",
    "    #im = ax.imshow(data, cmap=plt.cm.jet, origin='bottom')\n",
    "    #I haven't figured out how to create contours without also creating a plot\n",
    "    cs = ax.contour(x, y, data, 8, colors='w')\n",
    "    plt.clf()\n",
    "    \n",
    "    p = cs.levels#collections[0].get_paths()[0]\n",
    "    \n",
    "    \n",
    "    #Now, snatch the last level and use it to blur everything else out and find the center with a binary threshold\n",
    "    ret,thresh = cv2.threshold(data,p[-1],2000,cv2.THRESH_BINARY)\n",
    "\n",
    "    M = cv2.moments(thresh)\n",
    "    \n",
    "    \n",
    " \n",
    "    # calculate x,y coordinate of center\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return cX, np.shape(data)[0]-cY\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def compare_centers(image, disp, x_kin, y_kin, z):\n",
    "    \"\"\"\n",
    "    Compares the centeroid of the r-band image to that of the velocity dispersion 2D map,\n",
    "    also to the kinematic center (x_kin,y_kin).\n",
    "    It does this in terms of a physical distance in kpc, given the redshift of the galaxy.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    #Apply a 10x10 kernal to the image to filter out noise (its basically a low pass filter)\n",
    "    #to smooth things out\n",
    "    kernel = np.ones((10,10))\n",
    "\n",
    "    lp = ndimage.convolve(image.filled(fill_value=0), kernel)#was result\n",
    "    \n",
    "    \n",
    "    c=fit_2_gaussian(lp)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    img_cen_x = c[0]\n",
    "    img_cen_y = c[1]\n",
    "    \n",
    "    \n",
    "    #Do this whole thing again but for the velocity dispersion map\n",
    "    kernel = np.ones((10,10))\n",
    "\n",
    "    lp = ndimage.convolve(disp.filled(fill_value=0), kernel)#was result\n",
    "\n",
    "    c=fit_2_gaussian(lp)\n",
    "\n",
    "    disp_cen_x = c[0]\n",
    "    disp_cen_y = c[1]\n",
    "    \n",
    "    \n",
    "    kpc_arcsec=(cosmo.kpc_proper_per_arcmin(z).value/60)\n",
    "    spax_to_kpc = 0.5*kpc_arcsec\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return spax_to_kpc*np.sqrt((img_cen_x-disp_cen_x)**2+(img_cen_y-disp_cen_y)**2), spax_to_kpc*np.sqrt((img_cen_x-x_kin)**2+(img_cen_y-y_kin)**2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def extract_GALFIT_parameters(view, myr, im, run):\n",
    "    \"\"\"\n",
    "    This retrives the GALFIT predictors \n",
    "    \"\"\"\n",
    "    output='../LAURA_Sims/GALFIT_folder/out_'+str(run)+'_'+str(view)+'_'+str(myr)+'.fits'\n",
    "    try:\n",
    "        out=pyfits.open(output)\n",
    "    except FileNotFoundError:\n",
    "        #print('NO GALFIT FILEEEE')\n",
    "        STOP\n",
    "        \n",
    "        return 0, 0, 0\n",
    "\n",
    "    \n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            attempt=float(out[2].header['1_MAG'][0:5])\n",
    "            attempt_2=float(out[2].header['2_MAG'][0:5])\n",
    "        except ValueError:\n",
    "            return 0, 0, 0\n",
    "        if float(out[2].header['1_MAG'][0:5]) < float(out[2].header['2_MAG'][0:5]):\n",
    "        #this means the 1st one is brighter\n",
    "            inc=float(out[2].header['1_AR'][0:5])\n",
    "            r_e=float(out[2].header['1_RE'][0:5])\n",
    "            PA_img=(float(out[2].header['1_PA'][:5]))\n",
    "            \n",
    "        else:\n",
    "            inc=float(out[2].header['2_AR'][0:5])\n",
    "            r_e=float(out[2].header['2_RE'][0:5])\n",
    "            PA_img=(float(out[2].header['2_PA'][:5]))\n",
    "            \n",
    "    except KeyError or ValueError:#if there is no #2\n",
    "        try:\n",
    "            \n",
    "            inc=float(out[2].header['1_AR'][0:5])\n",
    "            r_e=float(out[2].header['1_RE'][0:5])\n",
    "            PA_img=(float(out[2].header['1_PA'][:5]))\n",
    "        except ValueError:\n",
    "            return 0, 0, 0\n",
    "        \n",
    "    return PA_img, inc, r_e\n",
    "\n",
    "\n",
    "def map_to_coords(map_cube, size):\n",
    "    \"\"\"\n",
    "    Converts coordinates to list form (in order to feed through kinemetry).\n",
    "    \"\"\"\n",
    "    x_list=[]\n",
    "    y_list=[]\n",
    "    vel_list=[]\n",
    "    vel_e_list=[]\n",
    "    sig_list=[]\n",
    "    sig_e_list=[]\n",
    "    \n",
    "    vel_dimension=map_cube[1].data\n",
    "    vel_e_dimension=map_cube[2].data\n",
    "    sig_dimension=map_cube[3].data\n",
    "    sig_e_dimension=map_cube[4].data\n",
    "    \n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            try:\n",
    "                value = vel_dimension[i,j]\n",
    "                if str(value) == '--':\n",
    "                    continue\n",
    "                vel_list.append(vel_dimension[i,j])\n",
    "                x_list.append(i)\n",
    "                y_list.append(j)\n",
    "                vel_e_list.append(vel_e_dimension[i,j])\n",
    "                sig_list.append(sig_dimension[i,j])\n",
    "                sig_e_list.append(sig_e_dimension[i,j])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            \n",
    "    \n",
    "    \n",
    "    return x_list, y_list, vel_list, vel_e_list, sig_list, sig_e_list\n",
    "\n",
    "\n",
    "\n",
    "def input_kinemetry(name, myr, view, x_list_after, y_list_after, vel_list_after, vel_e_list_after, sig_list_after, sig_e_list_after,  img_x, img_y, add_on, plot):\n",
    "    \"\"\"\n",
    "    Creates an input file for kinemetry (.txt file) that has columns of x and y coords, velocity, velocity dispersion,\n",
    "    and the errors on both of these values.\n",
    "    \"\"\"\n",
    "    file2=open('kinemetry_input_txt/kinemetry_input_'+str(name)+'_'+str(myr)+'_'+str(view)+'.txt','w')\n",
    "    file2.write('#'+'\\t'+'XBIN'+'\\t'+'YBIN'+'\\t'+'VEL'+'\\t'+'ER_VEL'+'\\t'+'SIG'+'\\t'+'ER_SIG'+'\\n')\n",
    "    \n",
    "    #These are the coordinates of the kinematic center of the galaxy\n",
    "    middle_x=img_x\n",
    "    middle_y=img_y\n",
    "    \n",
    "    #for some reason, kinemetry wants each row indexed\n",
    "    counter=1\n",
    "    \n",
    "    for i in range(len(x_list_after)):\n",
    "        if np.isnan(vel_list_after[i]):#mask these values by not including them in the file\n",
    "            #file2.write(str(counter)+'\\t'+str((middle_x-x_list_after[len(x_list_after)-1-i]))+'\\t'+str((middle_y-y_list_after[len(x_list_after)-1-i]))+'\\t')\n",
    "            #file2.write('--'+'\\t'+'--'+'\\t'+'--'+'\\t'+'--'+'\\n')\n",
    "        \n",
    "            continue\n",
    "        if vel_e_list_after[i]==0.0:#these are also list indices to mask\n",
    "            #file2.write(str(counter)+'\\t'+str((middle_x-x_list_after[len(x_list_after)-1-i]))+'\\t'+str((middle_y-y_list_after[len(x_list_after)-1-i]))+'\\t')\n",
    "            #file2.write('--'+'\\t'+'--'+'\\t'+'--'+'\\t'+'--'+'\\n')\n",
    "        \n",
    "            continue\n",
    "        file2.write(str(counter)+'\\t'+str((middle_x-x_list_after[len(x_list_after)-1-i]))+'\\t'+str((middle_y-y_list_after[len(x_list_after)-1-i]))+'\\t')\n",
    "        file2.write(str(vel_list_after[i])+'\\t'+str(vel_e_list_after[i])+'\\t'+str(sig_list_after[i])+'\\t'+str(sig_e_list_after[i])+'\\n')\n",
    "        counter +=1\n",
    "\n",
    "    file2.close()\n",
    "    \n",
    "    #optional, you can plot it to check\n",
    "    if plot=='yes':\n",
    "        file_check=open('kinemetry_input_txt/kinemetry_input_'+str(name)+'_'+str(myr)+'_'+str(view)+'.txt','w')\n",
    "        with open(file_check, 'r') as f:\n",
    "            data = f.readlines()\n",
    "\n",
    "\n",
    "            x_list=[]\n",
    "            y_list=[]\n",
    "            vel_list=[]\n",
    "            \n",
    "\n",
    "            for line in data:\n",
    "                words = line.split()\n",
    "                #print('words', words)\n",
    "\n",
    "                if words[4]=='*************************':\n",
    "                    continue\n",
    "                else:\n",
    "                    x_list.append(float(words[1]))\n",
    "                    y_list.append(float(words[2]))\n",
    "                    vel_list.append(float(words[3]))\n",
    "                    \n",
    "                    stel_vel[int(float(words[1])-size/2),int(float(words[2])-size/2)] = float(words[3])\n",
    "                    \n",
    "        plt.clf()\n",
    "        plt.imshow(stel_vel)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "def read_kin_maps(img, name, myr, view, dia, PA_img, size_cont, add_on, observed_velocity, kincen):\n",
    "   \n",
    "    file_velcirc='kinemetry_solution/myfile_v_'+str(name)+'_'+str(myr)+'_'+str(view)+'.txt'\n",
    "    \n",
    "    stel_vel_model=np.zeros((size,size))\n",
    "    stel_vel_model_tester=np.zeros((size,size))\n",
    "    stel_vel=np.zeros((size,size))\n",
    "    stel_sig_model=np.zeros((size,size))\n",
    "    stel_vel_kin_model=np.zeros((size,size))\n",
    "\n",
    "    try:\n",
    "        with open(file_velcirc, 'r') as f:\n",
    "            data = f.readlines()\n",
    "\n",
    "\n",
    "            x_list_model=[]\n",
    "            y_list_model=[]\n",
    "            vel_circ_model=[]\n",
    "            vel_kin_model=[]\n",
    "            vel_in=[]\n",
    "            vel_in_e=[]\n",
    "            vel_sig_model=[]\n",
    "            vel_kin_model=[]\n",
    "\n",
    "            for line in data:\n",
    "                words = line.split()\n",
    "                #print('words', words)\n",
    "\n",
    "                if words[4]=='*************************':\n",
    "                    continue\n",
    "                else:\n",
    "                    x_list_model.append(float(words[0]))\n",
    "                    y_list_model.append(float(words[1]))\n",
    "                    vel_in.append(float(words[2]))\n",
    "                    vel_in_e.append(float(words[3]))\n",
    "                    vel_circ_model.append(float(words[4]))\n",
    "                    vel_kin_model.append(float(words[5]))\n",
    "\n",
    "\n",
    "                    stel_vel[int(float(words[0])-size/2),int(float(words[1])-size/2)] = float(words[2])\n",
    "                    stel_vel_model[int(float(words[0])-size/2),int(float(words[1])-size/2)] = float(words[4])\n",
    "                    stel_vel_kin_model[int(float(words[0])-size/2),int(float(words[1])-size/2)] = float(words[5])\n",
    "                    #stel_vel_model_tester[int(float(words[1])-size/2),int(float(words[0])-size/2)] = float(words[4])\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "\n",
    "    '''\n",
    "    ~~~~~~~Sigs~~~~~~~\n",
    "    '''\n",
    "    stel_vel_model = ma.masked_where(stel_vel_model ==0, stel_vel_model)\n",
    "    stel_vel_kin_model = ma.masked_where(stel_vel_kin_model ==0, stel_vel_kin_model)\n",
    "    stel_vel = ma.masked_where(stel_vel ==0, stel_vel)\n",
    "    #stel_sig_model=((ma.masked_where(stel_sig_model==0, stel_sig_model)))\n",
    "    '''plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax0=fig.add_subplot(141)\n",
    "    im0 = ax0.imshow(img, cmap='afmhot_r')\n",
    "    plt.colorbar(im0)\n",
    "    ax0.set_title('Imaging', size=10)\n",
    "    \n",
    "    ax1=fig.add_subplot(142)\n",
    "    im1 = ax1.imshow((stel_vel), cmap='RdBu_r', vmin=-100, vmax=100)\n",
    "    plt.xlim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    plt.ylim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    plt.colorbar(im1)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(r'V$_{*}$', size=10)\n",
    "\n",
    "    ax2=fig.add_subplot(143)\n",
    "    im2 = ax2.imshow((stel_vel_model), cmap='RdBu_r', vmin=-100, vmax=100)\n",
    "    plt.xlim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    plt.ylim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    ax2.axis('off')\n",
    "    plt.colorbar(im2)\n",
    "    ax2.set_title(r'V$_{\\mathrm{kinemetry}}$', size=10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax3=fig.add_subplot(144)\n",
    "    im3 = ax3.imshow(((stel_vel - stel_vel_model)/stel_vel_model), cmap='RdBu_r')#, vmin=-100, vmax=100)\n",
    "    plt.xlim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    plt.ylim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    plt.colorbar(im3)\n",
    "    plt.annotate(str(round(resids,1)),xy=(0.05,0.05), xycoords='axes fraction')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    ax3.set_title(r'Velocity Residuals', size=10)\n",
    "    \n",
    "    #plt.colorbar(ax1)\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/velocity_model_compare_'+str(add_on)+'_'+str(myr)+'_'+str(view)+'.pdf',bbox_inches='tight' )\n",
    "    '''\n",
    "    stel_vel_model=ma.masked_where(stel_vel_model > 1000, stel_vel_model)\n",
    "    #stel_vel_model=ma.masked_where(stel_vel_model == 0, stel_vel_model)\n",
    "    \n",
    "    \n",
    "    '''Now open the file with kinematic PA, v_asym, s_asym'''\n",
    "    file_deets='kinemetry_solution/text_out_'+str(name)+'_'+str(myr)+'_'+str(view)+'.txt'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open(file_deets, 'r') as f:\n",
    "            data = f.readlines()\n",
    "            for line in data:\n",
    "                words = line.split()\n",
    "\n",
    "                PA_kin=float(words[0])\n",
    "                PA_kin_e=float(words[1])\n",
    "                v_asym=float(words[2])\n",
    "                s_asym=float(words[3])\n",
    "                K_asym=float(words[4])\n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "    \n",
    "    x=np.linspace(0,size, 1000)\n",
    "    ys_kin=[(j-size_cont/2)/math.tan(math.radians(PA_kin))+size_cont/2 for j in x]\n",
    "    plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax0 = fig.add_subplot(131)\n",
    "    im0 = ax0.imshow(observed_velocity, cmap='RdBu_r')#, vmin=-100, vmax=100)\n",
    "    plt.colorbar(im0, fraction=0.05)\n",
    "    ax0.scatter(np.shape(observed_velocity)[0]/2+kincen[0], np.shape(observed_velocity)[0]/2+kincen[1], color='black', marker='x')\n",
    "    ax0.set_title('$V_{*}$')\n",
    "    ax0.set_xlim([0,np.shape(observed_velocity)[0]])\n",
    "    ax0.set_ylim([0,np.shape(observed_velocity)[1]])\n",
    "    #ax0.axis('off')\n",
    "    \n",
    "    ax1 = fig.add_subplot(132)\n",
    "    im1 = ax1.imshow(stel_vel_model, cmap='RdBu_r')#, vmin=-100, vmax=100)\n",
    "    ax1.scatter(np.shape(observed_velocity)[0]/2+kincen[0], np.shape(observed_velocity)[0]/2+kincen[1], color='black', marker='x')\n",
    "    \n",
    "    ax1.set_xlim([0,np.shape(observed_velocity)[0]])\n",
    "    ax1.set_ylim([0,np.shape(observed_velocity)[1]])\n",
    "    \n",
    "    ax1.plot(x,ys_kin, color='black')\n",
    "    ax1.set_title('$V_{\\mathrm{model}}$')\n",
    "    plt.colorbar(im1, fraction=0.05)\n",
    "    #plt.title(r'\\texttt{kinemetry}')\n",
    "    #ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(133)\n",
    "    observed_mask = ma.masked_where(stel_vel_model==0, observed_velocity)\n",
    "    resids=np.sum(abs(observed_mask - stel_vel_model))/stel_vel_model.count()#np.mean(abs((stel_vel - stel_vel_model)/stel_vel_model))\n",
    "    #print('these are the resids', resids, 'n_spaxels', stel_vel_model.count())\n",
    "    im2 = ax2.imshow((observed_mask - stel_vel_model),  cmap='RdBu_r', vmin=-50, vmax=50)\n",
    "    ax2.scatter(np.shape(observed_velocity)[0]/2+kincen[0], np.shape(observed_velocity)[0]/2+kincen[1], color='black', marker='x')\n",
    "    \n",
    "    ax2.set_title('$V_{*} - V_{\\mathrm{model}}$')\n",
    "    plt.colorbar(im2, fraction=0.05)\n",
    "    ax2.set_xlim([0,np.shape(observed_velocity)[0]])\n",
    "    ax2.set_ylim([0,np.shape(observed_velocity)[1]])\n",
    "    #ax2.axis('off')\n",
    "    ax2.annotate('Residuals = '+str(round(resids,2)), xy=(0.05,0.85), xycoords='axes fraction')\n",
    "    \n",
    "    '''ax3 = fig.add_subplot(224)\n",
    "    im3 = ax3.imshow(abs(observed_mask - stel_vel_model),  norm=matplotlib.colors.LogNorm(),cmap='magma')\n",
    "    ax3.set_title('|$V_{*} - V_{\\mathrm{model}}$|')\n",
    "    plt.colorbar(im3, fraction=0.1)\n",
    "    \n",
    "    ax3.set_xlim([0,np.shape(observed_velocity)[0]])\n",
    "    ax3.set_ylim([0,np.shape(observed_velocity)[1]])\n",
    "    \n",
    "    ax3.axis('off')'''\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('kinemetry_result_'+str(name)+'_'+str(myr)+'_'+str(view)+'.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''PA_kin is measured from the south CCW, so -115 is actually 115 degrees to the CW direction from south'''\n",
    "    '''PA_imag is measured from the north CCW as well (argh)'''\n",
    "    PA_kin_moved = PA_kin#was 180+PA_kin\n",
    "    PA_img_moved = PA_img\n",
    "    \n",
    "    '''if abs(PA_img_moved-PA_kin_moved) > 90 and abs(PA_img_moved-PA_kin_moved) < 180:\n",
    "        new_delta_PA = 180-abs(PA_img_moved-PA_kin_moved)\n",
    "    else:\n",
    "        new_delta_PA = abs(PA_img_moved-PA_kin_moved)\n",
    "    if abs(PA_img_moved-PA_kin_moved) > 180:\n",
    "        new_delta_PA = abs(PA_img_moved-PA_kin_moved)-180'''\n",
    "    \n",
    "    new_delta_PA = abs(PA_img_moved-PA_kin_moved)\n",
    "    \n",
    "    \n",
    "    return new_delta_PA, v_asym, s_asym, K_asym, resids\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def make_table(counter, image, merger, myr, view, dPA, v_a, s_a,  resids, i, j, lambdar, epsilon, A,  A_2, dpos, dpos2):\n",
    "    #make_table(myr, view, out_kin[0], out_kin[1], out_kin[2], out_kin[3], out_kin[4])\n",
    "    if dPA > 90:\n",
    "        dPA = 180-dPA\n",
    "    file1.write(str(counter)+'\\t'+str(image)+'\\t'+str(merger)+'\\t'+str(round(myr,2))+'\\t'+str(view)+'\\t'+str(round(dPA,2))+'\\t'+str(round(v_a,2))+\n",
    "                    '\\t'+str(round(s_a,2))+'\\t'+str(round(resids,2))+'\\t'+\n",
    "                str(round(lambdar,2))+'\\t'+str(round(epsilon,2))+'\\t'+str(round(A,2))+'\\t'+str(round(A_2,2))+'\\t'+str(round(dpos,2))+'\\t'+str(round(dpos2,2))+'\\n')#was str(np.shape(vel_dist)[1]-1-j)\n",
    "    \n",
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def angular_momentum(velocity, dispersion, r_band, r_e):\n",
    "    #lambda_r_e = f*r*|v|/f*r*(v**2+sig**2)^(1/2)\n",
    "    #step 1 is to determine the effective radius in the r-band, which is from the full broadband image\n",
    "    #so the effective radius is in spaxels here (I think?) so just mask if sqrt(x_dist**2+y_dist**2)\n",
    "    #is greater than this amount\n",
    "    middle = np.shape(velocity)[0]/2\n",
    "    #print('middle', middle)\n",
    "    num=[]\n",
    "    denom=[]\n",
    "    for x in range(np.shape(velocity)[0]):\n",
    "        for y in range(np.shape(velocity)[1]):\n",
    "            distance_from_center = np.sqrt((x - middle)**2 + (y-middle)**2)\n",
    "            #print('distance', distance_from_center)\n",
    "            if distance_from_center > r_e:\n",
    "                continue\n",
    "            else:\n",
    "                num.append((r_band[x,y]*distance_from_center*abs(velocity[x,y])))\n",
    "                denom.append((r_band[x,y]*distance_from_center*np.sqrt(velocity[x,y]**2+dispersion[x,y]**2)))\n",
    "                #print('num', (r_band[x,y]*distance_from_center*abs(velocity[x,y])))\n",
    "                #print('denom',(r_band[x,y]*distance_from_center*np.sqrt(velocity[x,y]**2+dispersion[x,y]**2)))\n",
    "    #print('num', num)\n",
    "    #print('denom', denom)\n",
    "    \n",
    "    #print(np.nansum(num))\n",
    "    #print(np.nansum(denom))\n",
    "    lambdar = np.nansum(num)/np.nansum(denom)   \n",
    "    #print('lambdar', lambdar)\n",
    "    #summed_lambda = np.sum(lambdar)\n",
    "    return lambdar\n",
    "def ndim_grid(start,stop):\n",
    "    # Set number of dimensions\n",
    "    ndims = len(start)\n",
    "\n",
    "    # List of ranges across all dimensions\n",
    "    L = [np.arange(start[i],stop[i]) for i in range(ndims)]\n",
    "\n",
    "    # Finally use meshgrid to form all combinations corresponding to all \n",
    "    # dimensions and stack them as M x ndims array\n",
    "    return np.hstack((np.meshgrid(*L))).swapaxes(0,1).reshape(ndims,-1).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled\n"
     ]
    }
   ],
   "source": [
    "def radon_python_mod(vel_field, n_p, n_theta, r_ap, factor, plot):\n",
    "    \"\"\"\n",
    "    This section performs the radon transform, from Stark et al. 2018.\n",
    "    \n",
    "    It is a long calculation, because it first calculates the Absolute Radon Transform (R_AB) of the velocity field, \n",
    "    then it iterates for multiple choices of the kinematic center. It determines the kinematic center by minimizing\n",
    "    the asymmetry, A, of the Radon profile calculated from R_AB using a centroiding method.\n",
    "    \n",
    "    If the kinematic center is on the edge of the search grid of spaxels, it throws a flag and the code will rerun\n",
    "    this function after expanding the grid.\n",
    "    \n",
    "    \"\"\"\n",
    "    #It first converts the x and y coordinates into p and theta coordinates (circular)\n",
    "    #p is rho, which is the distance of the point on the velocity field from the kinematic center\n",
    "    p_list = np.linspace(-int(np.shape(vel_field)[0]/2)+5,int(np.shape(vel_field)[0]/2)-5, int(np.shape(vel_field)[0]/2)+1)#was 5\n",
    "    p_list = np.linspace(-int(np.shape(vel_field)[0]/2)+5, int(np.shape(vel_field)[0]/2)-5,n_p)#was 20\n",
    "   \n",
    "    #theta is the angle from the negative y axis CCW to the point on the velocity map.\n",
    "    theta_list = np.linspace(0, 180, n_theta)#was 10\n",
    "    \n",
    "    #It searches over a grid of coordinates around the photometric center to find the 'kinematic center',\n",
    "    #so it creates a 3x3 grid (from -3 to 3 including 0) in 2D\n",
    "    box_list=list(ndim_grid([-3, -3],[4,4]))\n",
    "    #If the kinematic center is not found on the first iteration, it expands the dimensions of the grid\n",
    "    #by a factor of 2 upon rerunning.\n",
    "    box_list=[factor*x for x in box_list]\n",
    "    \n",
    "    \n",
    "    if plot=='yes':\n",
    "        #Here I create a X and Y meshgrid type list of these points, since this is a rough approximation of the \n",
    "        #full grid of points in order to later plot what is happening.\n",
    "        X_list=[]\n",
    "        Y_list=[]\n",
    "\n",
    "        for j in range(len(box_list)):\n",
    "\n",
    "            X_list.append(int(np.shape(vel_field)[0]/2+box_list[j][0]))#-10+box_list[b][0])\n",
    "            Y_list.append(int(np.shape(vel_field)[1]/2+box_list[j][1]))#-10+box_list[b][1])\n",
    "        \n",
    "    #print('X_list', X_list)\n",
    "    #print('Y_list', Y_list)\n",
    "    \n",
    "    #creates empty lists that will be populated with R_AB, and all other derived quantities from this for every \n",
    "    #rho, theta point.\n",
    "    A_list=[]\n",
    "    A_e_list=[]\n",
    "    A_2_list=[]\n",
    "    R_AB_list=[]\n",
    "    theta_hat_list=[]\n",
    "    theta_hat_e_list=[]\n",
    "    \n",
    "    \n",
    "    #First run it for just the center one, index b=24 in order to normalize relative to the center\n",
    "    #later on in the calculation of A.\n",
    "    R_AB=[]\n",
    "    b=24\n",
    "    \n",
    "    for i in range(len(p_list)):\n",
    "        for j in range(len(theta_list)):\n",
    "            #\n",
    "            X = int(p_list[i]*math.cos(math.radians(theta_list[j]))+np.shape(vel_field)[0]/2-0.5+box_list[b][0])#-10+box_list[b][0])\n",
    "            Y = int(p_list[i]*math.sin(math.radians(theta_list[j]))+np.shape(vel_field)[1]/2-0.5+box_list[b][1])#-10+box_list[b][1])\n",
    "            \n",
    "\n",
    "            '''We have an X and a Y and a theta (slope) so we should be able to get the intercept'''\n",
    "            '''And then two more points on either end'''\n",
    "\n",
    "\n",
    "            '''But we only want to calculate for things that are on the circle'''\n",
    "\n",
    "            try:\n",
    "                #if this point exists in the velocity field then you can continue\n",
    "                test_value = vel_field[X,Y]\n",
    "            except IndexError:\n",
    "                R_AB.append(-1000)\n",
    "                continue\n",
    "            if np.isnan(vel_field[X,Y]):\n",
    "                R_AB.append(-1000)\n",
    "                STOP2\n",
    "                continue\n",
    "\n",
    "            if str(vel_field[X,Y]) == '--':\n",
    "                R_AB.append(-1000)\n",
    "                continue\n",
    "            #calculate the slope of the line segment from the kinematic center (in this case the photometric center)\n",
    "            #to the given point\n",
    "            deltay = Y - np.shape(vel_field)[1]/2\n",
    "            deltax = X - np.shape(vel_field)[0]/2\n",
    "            #draw a line perpendicular to this; the radon transform will be calculated along this line\n",
    "            slope_p = math.tan(math.radians(theta_list[j]+90))#-deltax/deltay\n",
    "            #draw a line from the point to where it intersects the bottom left of the map, which is the new origin\n",
    "            intercept = Y - slope_p*X\n",
    "\n",
    "\n",
    "\n",
    "            if slope_p > 1000:\n",
    "                #vertical, so calculate along one value of X for the entire length of y\n",
    "                x_min = X\n",
    "                x_max = X\n",
    "                y_min = 0\n",
    "                y_max = np.shape(vel_field)[0]\n",
    "            else:\n",
    "                x_min = 0\n",
    "                x_max = np.shape(vel_field)[0]\n",
    "                y_min = intercept\n",
    "                y_max = intercept+slope_p*x_max\n",
    "\n",
    "            #This neat line draws a line through a given set of coordinates\n",
    "            bres_list = list(bresenham(int(x_min), int(y_min), int(x_max), int(y_max)))\n",
    "\n",
    "            #to calculate the absolute Bounded Radon Transform, do this for all points that are within r_e/2 of the center\n",
    "            #of the line:\n",
    "            vel_append=[]\n",
    "            for k in range(len(bres_list)):\n",
    "                if bres_list[k][0] < 0 or bres_list[k][1] < 0:\n",
    "                    continue\n",
    "                if np.sqrt((bres_list[k][0]-X)**2+(bres_list[k][1]-Y)**2) > r_e/2:\n",
    "                    continue\n",
    "               \n",
    "                try:\n",
    "                    vel_append.append(vel_field[bres_list[k][1], bres_list[k][0]])\n",
    "                    \n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "            #clean it up, no masked values in here!\n",
    "            vel_append_clean=[]\n",
    "            for k in range(len(vel_append)):\n",
    "                if ma.is_masked(vel_append[k]):\n",
    "                    continue\n",
    "                else:\n",
    "                    vel_append_clean.append(vel_append[k])\n",
    "\n",
    "\n",
    "            #finally, create R_AB by summing all of these velocity differences\n",
    "            if vel_append_clean:\n",
    "                inside=vel_append_clean-np.mean(vel_append_clean)\n",
    "                R_AB.append(np.sum(np.abs(inside)))\n",
    "            else:\n",
    "                R_AB.append(-1000)\n",
    "\n",
    "\n",
    "    R_AB=ma.masked_where(np.isnan(R_AB), R_AB)\n",
    "    R_AB = ma.masked_where(R_AB==-1000, R_AB)\n",
    "\n",
    "    \n",
    "    R_AB_array = np.reshape(R_AB, (len(p_list),len(theta_list)))\n",
    "\n",
    "\n",
    "    #Now, extract the R_AB value at each rho value across all theta values.\n",
    "    #This creates the Radon profile; the estimated value of theta hat that minimizes R_AB at each value of rho.\n",
    "    #We minimize R_AB because we want the theta value at each rho that \n",
    "\n",
    "    #these are the estimated values of theta that are best fit for a value of rho\n",
    "    theta_hat=[]\n",
    "    theta_hat_e=[]\n",
    "\n",
    "    for l in range(len(p_list)):\n",
    "\n",
    "        marginalized = R_AB_array[l,:]\n",
    "        marginalized = ma.masked_where(marginalized<1e-4, marginalized)\n",
    "        count = len([i for i in marginalized if i > 1e-3])\n",
    "        #count up how many elements are in the row of R_AB --> if it is less than 6, don't measure it\n",
    "        #because it will cause an error when trying to fit a Gaussian, k = n+1\n",
    "        if count < 6:\n",
    "            theta_hat.append(0)\n",
    "            theta_hat_e.append(0)\n",
    "            continue\n",
    "\n",
    "        if ma.is_masked(marginalized)==True:\n",
    "            theta_hat.append(0)\n",
    "            theta_hat_e.append(0)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            #initially, try to fit a negative gaussian to determine theta hat\n",
    "            popt,pcov = curve_fit(gauss,theta_list,marginalized,p0=[-abs(np.min(marginalized)-np.max(marginalized)),theta_list[list(marginalized).index(np.min(marginalized))],20,np.mean(marginalized)])\n",
    "            append_value = popt[1]\n",
    "            \n",
    "            \n",
    "            \n",
    "        except RuntimeError or OptimizeError: \n",
    "            theta_hat.append(0)\n",
    "            theta_hat_e.append(0)\n",
    "\n",
    "            continue\n",
    "            \n",
    "            \n",
    "\n",
    "        #if the code fits a positive Gaussian, try a new guess for the correct theta hat, the second smallest value       \n",
    "        if (popt[0]>0):\n",
    "            try:\n",
    "                popt,pcov = curve_fit(gauss,theta_list,marginalized,p0=[-abs(np.min(marginalized)-np.max(marginalized)),theta_list[list(marginalized).index(sorted(marginalized)[1])],20,np.mean(marginalized)])\n",
    "                append_value = popt[1]\n",
    "                if popt[0] > 0:\n",
    "                    #if this doesn't work, quit and move on\n",
    "\n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "            except RuntimeError or OptimizeError :\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "\n",
    "                continue\n",
    "        \n",
    "        #sometimes, it is necessary to shift the xs because the peak is at 180, which is right at the edge\n",
    "        if ((popt[1] - 3*np.sqrt(pcov[1][1])) < 0) or ((popt[1] + 3*np.sqrt(pcov[1][1])) > 180):\n",
    "            theta_list_shifted = theta_list+find_nearest(theta_list,90)\n",
    "            index_1 = list(theta_list).index(find_nearest(theta_list,90))\n",
    "            new_marginalized = np.concatenate((marginalized[index_1:], marginalized[:index_1]))\n",
    "\n",
    "            try:\n",
    "                popt,pcov = curve_fit(gauss,theta_list_shifted,new_marginalized,p0=[-abs(np.min(new_marginalized)-np.max(new_marginalized)),theta_list_shifted[list(new_marginalized).index(np.min(new_marginalized))],20,np.mean(new_marginalized)])\n",
    "                \n",
    "\n",
    "                if popt[0] > 0:\n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "\n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "                if popt[1] > 180:\n",
    "                    append_value = popt[1]-180\n",
    "                else:\n",
    "                    append_value = popt[1]\n",
    "\n",
    "            except RuntimeError or OptimizeError :\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "\n",
    "                continue\n",
    "            \n",
    "        theta_hat.append(append_value)\n",
    "        theta_hat_e.append(np.sqrt(pcov[1][1]))\n",
    "\n",
    "    #now to calculate A, it is necessary to sum the values of theta hat at a mirror image of themselves\n",
    "    #across p=0\n",
    "    delta_theta_sum=[]\n",
    "    delta_theta_sum_e=[]\n",
    "\n",
    "\n",
    "    for l in range(int(len(p_list)/2)):\n",
    "        if (theta_hat[0+l]==0) or (theta_hat[-1-l]==0) or (abs(theta_hat[0+l])>180) or (abs(theta_hat[-1-l]) > 180):\n",
    "\n",
    "            delta_theta_sum.append(0)\n",
    "            delta_theta_sum_e.append(0)\n",
    "        else:\n",
    "            if abs(theta_hat[0+l]-theta_hat[-1-l]) > 90:\n",
    "                #because the maximum you can be apart is 90\n",
    "                inside = 180 - abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "            else:\n",
    "                inside = abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "\n",
    "            delta_theta_sum.append(inside)\n",
    "            #I would also like to have an error estimate on this quantity:\n",
    "            delta_theta_sum_e.append(np.sqrt((theta_hat_e[0+l])**2+\n",
    "                                         (theta_hat_e[-1-l])**2))\n",
    "    \n",
    "\n",
    "\n",
    "    delta_theta_sum_masked=ma.masked_where(np.array(delta_theta_sum)==0, delta_theta_sum)\n",
    "\n",
    "    \n",
    "\n",
    "    OG_weight=ma.count(delta_theta_sum_masked)\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax0 = fig.add_subplot(111)\n",
    "    if plot=='yes':\n",
    "        \n",
    "        im0 = ax0.imshow(np.flipud(vel_field), cmap='RdBu_r')\n",
    "    \n",
    "    \n",
    "    #Okay now do this for all the other positions in box_list\n",
    "    A_list=[]\n",
    "    A_e_list=[]\n",
    "    \n",
    "    A_2_list=[]\n",
    "    R_AB_list=[]\n",
    "    theta_hat_list=[]\n",
    "    theta_hat_e_list=[]\n",
    "\n",
    "    \n",
    "            \n",
    "    A_list=[]\n",
    "    A_e_list=[]\n",
    "    A_2_list=[]\n",
    "    R_AB_list=[]\n",
    "    theta_hat_list=[]\n",
    "    theta_hat_e_list=[]\n",
    "    \n",
    "    X_list_real=[]\n",
    "    Y_list_real=[]\n",
    "    \n",
    "\n",
    "    for b in range(len(box_list)):\n",
    "        R_AB=[]\n",
    "        X_list_real.append(np.shape(vel_field)[0]/2-0.5+box_list[b][0])\n",
    "        Y_list_real.append(np.shape(vel_field)[1]/2-0.5+box_list[b][1])\n",
    "        for i in range(len(p_list)):\n",
    "            for j in range(len(theta_list)):\n",
    "                #\n",
    "                X = int(p_list[i]*math.cos(math.radians(theta_list[j]))+np.shape(vel_field)[0]/2-0.5+box_list[b][0])#-10+box_list[b][0])\n",
    "                Y = int(p_list[i]*math.sin(math.radians(theta_list[j]))+np.shape(vel_field)[1]/2-0.5+box_list[b][1])#-10+box_list[b][1])\n",
    "                \n",
    "                try:\n",
    "                    #if this point exists in the velocity field then you can continue\n",
    "                    test_value = vel_field[X,Y]\n",
    "                except IndexError:\n",
    "                    R_AB.append(-1000)\n",
    "                    continue\n",
    "                if np.isnan(vel_field[X,Y]):\n",
    "                    R_AB.append(-1000)\n",
    "                    STOP2\n",
    "                    continue\n",
    "\n",
    "                if str(vel_field[X,Y]) == '--':\n",
    "                    R_AB.append(-1000)\n",
    "                    continue\n",
    "                #calculate the slope of the line segment from the kinematic center (in this case the photometric center)\n",
    "                #to the given point\n",
    "                deltay = Y - np.shape(vel_field)[1]/2\n",
    "                deltax = X - np.shape(vel_field)[0]/2\n",
    "                #draw a line perpendicular to this; the radon transform will be calculated along this line\n",
    "                slope_p = math.tan(math.radians(theta_list[j]+90))#-deltax/deltay\n",
    "                #draw a line from the point to where it intersects the bottom left of the map, which is the new origin\n",
    "                intercept = Y - slope_p*X\n",
    "\n",
    "\n",
    "\n",
    "                if slope_p > 1000:\n",
    "                    #vertical, so calculate along one value of X for the entire length of y\n",
    "                    x_min = X\n",
    "                    x_max = X\n",
    "                    y_min = 0\n",
    "                    y_max = np.shape(vel_field)[0]\n",
    "                else:\n",
    "                    x_min = 0\n",
    "                    x_max = np.shape(vel_field)[0]\n",
    "                    y_min = intercept\n",
    "                    y_max = intercept+slope_p*x_max\n",
    "\n",
    "                #This neat line draws a line through a given set of coordinates\n",
    "                bres_list = list(bresenham(int(x_min), int(y_min), int(x_max), int(y_max)))\n",
    "\n",
    "                \n",
    "                #to calculate the absolute Bounded Radon Transform, do this for all points that are within r_e/2 of the center\n",
    "                #of the line:\n",
    "                vel_append=[]\n",
    "                for k in range(len(bres_list)):\n",
    "                    if bres_list[k][0] < 0 or bres_list[k][1] < 0:\n",
    "                        continue\n",
    "                    if np.sqrt((bres_list[k][0]-X)**2+(bres_list[k][1]-Y)**2) > r_e/2:\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "\n",
    "                        vel_append.append(vel_field[bres_list[k][1], bres_list[k][0]])\n",
    "                        #vel_new[bres_list[j][1], bres_list[j][0]] = vel_field[bres_list[j][1], bres_list[j][0]]\n",
    "                    except IndexError:\n",
    "                        continue\n",
    "\n",
    "                #clean it up, no masked values in here!\n",
    "                vel_append_clean=[]\n",
    "                for k in range(len(vel_append)):\n",
    "                    if ma.is_masked(vel_append[k]):\n",
    "                        continue\n",
    "                    else:\n",
    "                        vel_append_clean.append(vel_append[k])\n",
    "\n",
    "\n",
    "                #finally, create R_AB by summing all of these velocity differences\n",
    "                if vel_append_clean:\n",
    "                    inside=vel_append_clean-np.mean(vel_append_clean)\n",
    "                    R_AB.append(np.sum(np.abs(inside)))\n",
    "                else:\n",
    "                    R_AB.append(-1000)\n",
    "\n",
    "\n",
    "        R_AB=ma.masked_where(np.isnan(R_AB), R_AB)\n",
    "        R_AB = ma.masked_where(R_AB==-1000, R_AB)\n",
    "\n",
    "\n",
    "        R_AB_array = np.reshape(R_AB, (len(p_list),len(theta_list)))\n",
    "\n",
    "\n",
    "        #Now, extract the R_AB value at each rho value across all theta values.\n",
    "        #This creates the Radon profile; the estimated value of theta hat that minimizes R_AB at each value of rho.\n",
    "        #We minimize R_AB because we want the theta value at each rho that \n",
    "\n",
    "        #these are the estimated values of theta that are best fit for a value of rho\n",
    "        theta_hat=[]\n",
    "        theta_hat_e=[]\n",
    "\n",
    "        for l in range(len(p_list)):\n",
    "\n",
    "            marginalized = R_AB_array[l,:]\n",
    "            marginalized = ma.masked_where(marginalized<1e-4, marginalized)\n",
    "            count = len([i for i in marginalized if i > 1e-3])\n",
    "            #count up how many elements are in the row of R_AB --> if it is less than 6, don't measure it\n",
    "            #because it will cause an error when trying to fit a Gaussian, k = n+1\n",
    "            if count < 6:\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "                continue\n",
    "\n",
    "            if ma.is_masked(marginalized)==True:\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                popt,pcov = curve_fit(gauss,theta_list,marginalized,p0=[-abs(np.min(marginalized)-np.max(marginalized)),theta_list[list(marginalized).index(np.min(marginalized))],20,np.mean(marginalized)])\n",
    "                append_value = popt[1]\n",
    "\n",
    "                \n",
    "\n",
    "            #sometimes, it is necessary to shift the xs because the peak is at 180, which is right at the cutoff\n",
    "            except RuntimeError or OptimizeError: \n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "\n",
    "                continue\n",
    "                \n",
    "\n",
    "\n",
    "                    \n",
    "            if (popt[0]>0):\n",
    "                try:\n",
    "                    popt,pcov = curve_fit(gauss,theta_list,marginalized,p0=[-abs(np.min(marginalized)-np.max(marginalized)),theta_list[list(marginalized).index(sorted(marginalized)[1])],20,np.mean(marginalized)])\n",
    "                    append_value = popt[1]\n",
    "                    if popt[0] > 0:\n",
    "\n",
    "\n",
    "                        theta_hat.append(0)\n",
    "                        theta_hat_e.append(0)\n",
    "\n",
    "                        continue\n",
    "\n",
    "\n",
    "                except RuntimeError or OptimizeError :\n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "\n",
    "                    continue\n",
    "            if ((popt[1] - 3*np.sqrt(pcov[1][1])) < 0) or ((popt[1] + 3*np.sqrt(pcov[1][1])) > 180):\n",
    "                theta_list_shifted = theta_list+find_nearest(theta_list,90)\n",
    "                index_1 = list(theta_list).index(find_nearest(theta_list,90))\n",
    "                new_marginalized = np.concatenate((marginalized[index_1:], marginalized[:index_1]))\n",
    "\n",
    "                try:\n",
    "                    popt,pcov = curve_fit(gauss,theta_list_shifted,new_marginalized,p0=[-abs(np.min(new_marginalized)-np.max(new_marginalized)),theta_list_shifted[list(new_marginalized).index(np.min(new_marginalized))],20,np.mean(new_marginalized)])\n",
    "                    \n",
    "                    if popt[0] > 0:\n",
    "                        theta_hat.append(0)\n",
    "                        theta_hat_e.append(0)\n",
    "\n",
    "                        continue\n",
    "\n",
    "                    \n",
    "                    if popt[1] > 180:\n",
    "                        append_value = popt[1]-180\n",
    "                    else:\n",
    "                        append_value = popt[1]\n",
    "\n",
    "                except RuntimeError or OptimizeError :\n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "\n",
    "                    continue\n",
    "\n",
    "            theta_hat.append(append_value)\n",
    "            theta_hat_e.append(np.sqrt(pcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        delta_theta_sum=[]\n",
    "        delta_theta_sum_e=[]\n",
    "        \n",
    "        \n",
    "        for l in range(int(len(p_list)/2)):\n",
    "            if (theta_hat[0+l]==0) or (theta_hat[-1-l]==0) or (abs(theta_hat[0+l])>180) or (abs(theta_hat[-1-l]) > 180):\n",
    "                \n",
    "                delta_theta_sum.append(0)\n",
    "                delta_theta_sum_e.append(0)\n",
    "            else:\n",
    "                \n",
    "                \n",
    "                if abs(theta_hat[0+l]-theta_hat[-1-l]) > 90:\n",
    "                    #because the maximum you can be apart is 90\n",
    "                    inside = 180 - abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "                else:\n",
    "                    inside = abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "                \n",
    "                delta_theta_sum.append(inside)\n",
    "                delta_theta_sum_e.append(np.sqrt((theta_hat_e[0+l])**2+\n",
    "                                             (theta_hat_e[-1-l])**2))\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "        theta_hat_mask = ma.masked_where(theta_hat==0, theta_hat)\n",
    "        theta_hat_mask = ma.masked_where(abs(theta_hat_mask) >180, theta_hat_mask)\n",
    "        \n",
    "        theta_hat_list.append(theta_hat_mask)\n",
    "        theta_hat_e_list.append(theta_hat_e)\n",
    "        \n",
    "        delta_theta_sum_masked=ma.masked_where(np.array(delta_theta_sum)==0, delta_theta_sum)\n",
    "\n",
    "        #A is weighted by the A value of the center of the map\n",
    "        A = ((ma.sum(delta_theta_sum)/(ma.count(delta_theta_sum_masked)**2)))*OG_weight\n",
    "       \n",
    "        A_percent_e = []\n",
    "        for l in range(len(delta_theta_sum_e)):\n",
    "            if delta_theta_sum[l] != 0 :\n",
    "                A_percent_e.append((delta_theta_sum_e[l])**2)\n",
    "        A_abs_error = np.sqrt(np.sum(A_percent_e))#so this is on the numerator of the A error only\n",
    "        A_error = (A_abs_error/ma.sum(delta_theta_sum))*A\n",
    "       \n",
    "        \n",
    "        \n",
    "        A_list.append(A)\n",
    "        \n",
    "        \n",
    "        A_e_list.append(A_error)\n",
    "\n",
    "        #Also calculates the other types of asymmetry:\n",
    "        #A_2\n",
    "        delta_theta_sum=ma.masked_where(np.array(delta_theta_sum)==0, delta_theta_sum)\n",
    "        delta_theta_sum_e=ma.masked_where(np.array(delta_theta_sum_e)==0, delta_theta_sum_e)\n",
    "        \n",
    "        \n",
    "        A_2 = ma.sum(delta_theta_sum/delta_theta_sum_e)\n",
    "        \n",
    "        \n",
    "        \n",
    "        A_2_list.append(A_2)\n",
    "        \n",
    "        R_AB_list.append(R_AB_array)\n",
    "        \n",
    "    \n",
    "      \n",
    "    \n",
    "    \n",
    "    A_list = np.array(A_list)\n",
    "    A_list = ma.masked_where(np.isnan(A_list), A_list)\n",
    "    \n",
    "    A_list_array = np.reshape(np.array(A_list), (7,7))\n",
    "    A_e_list_array = np.reshape(np.array(A_e_list), (7,7))\n",
    "\n",
    "    \n",
    "\n",
    "    x = factor*np.linspace(0, np.shape(A_list_array)[0]-1,np.shape(A_list_array)[0])+30-2*(factor-1)\n",
    "    y = (factor*6-factor*np.linspace(0, np.shape(A_list_array)[1]-1, np.shape(A_list_array)[1]))+30-2*(factor-1)\n",
    "    if min(X_list_real) != min(x):\n",
    "        #this is improper scaling\n",
    "        print('x and y', x, y)\n",
    "    \n",
    "        print('this is what it should match X_list', X_list_real, Y_list_real)\n",
    "    \n",
    "        STOP\n",
    "    \n",
    "    \n",
    "    x, y = np.meshgrid(x, y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cs = ax0.contour(x,y, np.rot90(A_list_array), 5, colors='orange')#was 5\n",
    "    p = cs.levels#collections[0].get_paths()[0]\n",
    "    \n",
    "    im1 = ax0.scatter(X_list_real,Y_list_real,c=A_list, s=30, zorder=100)\n",
    "    \n",
    "    plt.colorbar(im0)\n",
    "    \n",
    "    #Now, snatch the last level and use it to blur everything else out and find the center\n",
    "    #now fill with zeros and do your best to turn into a binary bitmask'''\n",
    "    ret,thresh = cv2.threshold(np.rot90(A_list_array),p[0],100,cv2.THRESH_BINARY_INV)\n",
    "    M = cv2.moments(thresh)\n",
    "\n",
    "\n",
    "\n",
    "    # calculate x,y coordinate of center\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('this is the center', cX, cY)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''plt.clf()\n",
    "    im=plt.scatter(X_list,Y_list,c=A_list, s=50, cmap='Reds')\n",
    "    \n",
    "    cont=plt.contour(x,y, (A_list_array), 5, colors='orange')#was 5\n",
    "    plt.colorbar(im)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.clf()\n",
    "    im=plt.scatter(X_list,Y_list,c=A_e_list, s=50, cmap='Reds')\n",
    "    \n",
    "    plt.colorbar(im)\n",
    "    plt.title('error array')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.imshow(thresh)\n",
    "    plt.scatter(cX,(6-cY), marker='x', color='red')\n",
    "    plt.show()'''\n",
    "    \n",
    "    \n",
    "    '''x = factor*np.linspace(0, np.shape(A_list_array)[0]-1,np.shape(A_list_array)[0])+30-2*(factor-1)\n",
    "    y = (factor*6-factor*np.linspace(0, np.shape(A_list_array)[1]-1, np.shape(A_list_array)[1]))+30-2*(factor-1)\n",
    "    '''\n",
    "    \n",
    "    x_match = cX+30-2*(factor-1)\n",
    "    y_match = (6*factor-cY)+30-2*(factor-1)\n",
    "    \n",
    "    print('this is the cX and cY', x_match, y_match)\n",
    "    \n",
    "    \n",
    "    plt.scatter(x_match, y_match, marker='x', color='red', zorder=105)\n",
    "    '''plt.xlim([20,40])\n",
    "    plt.ylim([20,40])'''\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    plt.imshow(np.flipud(thresh))\n",
    "    plt.scatter(cX,6-cY, marker='x', color='red')\n",
    "    \n",
    "    x = np.linspace(0, np.shape(A_list_array)[0]-1,np.shape(A_list_array)[0])\n",
    "    y = (6-np.linspace(0, np.shape(A_list_array)[1]-1, np.shape(A_list_array)[1]))\n",
    "    x, y = np.meshgrid(x,y)\n",
    "    \n",
    "    plt.contour(x,y, np.rot90(A_list_array), 5, colors='orange')#was 5\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''now find the min index of this'''\n",
    "    for ii in range(len(X_list)):\n",
    "        if X_list[ii]==find_nearest(np.array(X_list),x_match) and Y_list[ii]==find_nearest(np.array(Y_list),y_match):\n",
    "            min_index = ii\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    if factor ==1:\n",
    "        if abs(box_list[min_index][0])>2 or abs(box_list[min_index][1])>2:\n",
    "            #then we are on the edge\n",
    "            expand=1\n",
    "        else:\n",
    "            expand=0\n",
    "    else:\n",
    "        if abs(box_list[min_index][0])>5 or abs(box_list[min_index][1])>5:\n",
    "            min_index=24\n",
    "        expand=0\n",
    "        \n",
    "    \n",
    "    print('this is the box list spot', box_list[min_index], 'and the min coordinates', np.shape(vel_field)[0]/2-0.5+box_list[min_index][0],np.shape(vel_field)[1]/2-0.5+box_list[min_index][1])\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    return box_list[min_index],R_AB_list[min_index], A_list[min_index],  A_2_list[min_index],p_list, theta_list, theta_hat_list[min_index], theta_hat_e_list[min_index], expand\n",
    "print('compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "os.chdir(os.path.expanduser('/Users/beckynevin/Documents/Backup_My_Book/My_Passport_backup/Kinematics/'))\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "\n",
    "view_list=[0,1,2,3,4,5,6]#1\n",
    "\n",
    "\n",
    "\n",
    "myr_list=[170,180,185,190,205,210]\n",
    "myr_list=[5,10,30,50,100,200]\n",
    "\n",
    "myr_list=[20,40,70,80,100,120,140,150,170,180,190,210,220,230,235,237,\n",
    "     240,242,245,247,250,252,255,257,262,265,270,275,280,285,\n",
    "     287,288,289,290,295,300,305]\n",
    "\n",
    "myr_list=[235,237,\n",
    "     240,242,245,247,250,252,255,257,262,265,270,275,280,285,\n",
    "     287,288,289,290,295,300,305]\n",
    "\n",
    "\n",
    "\n",
    "myr_list=[220, 225, 230, 240, 250, 260,265,275,285, 295,305,311, 315,320,\n",
    "     5,10,20,30,40,60,80,100,120,140,160]\n",
    "\n",
    "#myr_list=[185]\n",
    "#myr_list=[200,205,210]\n",
    "\n",
    "#myr_list=[5,10,20,30,40,50,60,100,200]\n",
    "#myr_list=[205,210]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "myr_list=[ 220, 225, 230, 240, 250, 260,265,275,285, 295,305,311, 315,320,\n",
    "     5,10,20,30,40,60,80,100,120,140,160]\n",
    "\n",
    "myr_list=[5,10,30,50,200]\n",
    "myr_list=[170,180,185,190,205,210]\n",
    "\n",
    "myr_list=[5,10,20,30,40,50,60,100,200]\n",
    "\n",
    "myr_list=[5,40,60,100,200,300,400,410,420,\n",
    "     600,640,700,800,840,900,940,980,1000,1020,1040,1060,1080,1100,1140,\n",
    "     1145,1150,1155,1160,1165,1168]\n",
    "\n",
    "merger=1\n",
    "\n",
    "#\n",
    "#myr_list=[   5,30,60,90,100,120,150,180,200]\n",
    "\n",
    "\n",
    "'''myr_list=[5,40,60,100,200,300,400,410,420,\n",
    "     600,640,700,800,840,900,940,980,1000,1020,1040,1060,1080,1100,1140,\n",
    "     1145,1150,1155,1160,1165,1168]'''\n",
    "\n",
    "myr_list=[20,40,70,80,100,120,140,150,170,180,190,210,220,230,235,237,\n",
    "     240,242,245,247,250,252,255,257,262,265,270,275,280,285,\n",
    "     287,288,289,290,295,300,305]\n",
    "\n",
    "myr_list=[245,247,250,252,255,257,262,265,270,275,280,285,\n",
    "     287,288,289,290,295,300,305]\n",
    "\n",
    "myr_list=[5]#,60,90,120,150,180,210,240,270,300,320,340,360,380,400,420,440,460,480,500]\n",
    "myr_list=[185]\n",
    "view_list=[0,1,2,3,4,5,6]\n",
    "\n",
    "#view_list=[2]\n",
    "#myr_list=[90]\n",
    "\n",
    "gas='no'\n",
    "\n",
    "adds='NONSCATTER_kin_correct_noise_conv'#stellar_kinematics_NONSCATTER_kin_correct_noi\n",
    "#run='fg3_m12_iso0.5'\n",
    "#run='fg3_m12_agnx0'\n",
    "#run='fg3_m15_iso1'\n",
    "run='fg3_m12_agnx0'\n",
    "\n",
    "file1=open('LDA_kin_rerecenter_'+str(run)+'.txt','w')\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "counter=0\n",
    "z=0.03\n",
    "\n",
    "for i in range(len(myr_list)):\n",
    "    myr=myr_list[i]\n",
    "    v_offsets=[]\n",
    "    for j in range(len(view_list)):\n",
    "        im=0\n",
    "        view=view_list[j]\n",
    "        print('myr, view', myr, view)\n",
    "        if run=='fg3_m10':\n",
    "            if myr > 420:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_late/broadband_'+str(myr)+'.fits')\n",
    "            else:\n",
    "                if myr < 10:\n",
    "                    im = pyfits.open('../LAURA_Sims/q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_00'+str(myr)+'.fits')\n",
    "                else:\n",
    "                    if myr < 100:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_0'+str(myr)+'.fits')\n",
    "                    else:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_'+str(myr)+'.fits')\n",
    "        \n",
    "        \n",
    "        if run=='fg3_m13':\n",
    "            if myr > 140:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.333_fg0.3_allrx10_sunruns/hires_kin_late/broadband_'+str(myr)+'.fits')\n",
    "            else:\n",
    "                if myr < 10:\n",
    "                    im = pyfits.open('../LAURA_Sims/q0.333_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_00'+str(myr)+'.fits')\n",
    "                else:\n",
    "                    if myr < 100:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.333_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_0'+str(myr)+'.fits')\n",
    "                    else:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.333_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_'+str(myr)+'.fits')\n",
    "        \n",
    "        if run=='fg3_m12_iso0.5':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            im = pyfits.open('../LAURA_Sims/isolated_galaxies/m0.5_fg0.3/broadband_'+prefix+str(myr)+'.fits')\n",
    "            \n",
    "        \n",
    "        if run=='fg3_m12_iso1':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            im = pyfits.open('../LAURA_Sims/isolated_galaxies/m1_fg0.3/broadband_'+prefix+str(myr)+'.fits')\n",
    "            \n",
    "        if run=='fg3_m12':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            if myr < 170:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_'+prefix+str(myr)+'.fits')\n",
    "            else:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.5_fg0.3_allrx10_sunruns/hires_kin/broadband_'+prefix+str(myr)+'.fits')\n",
    "        if run=='fg3_m12_agnx0':\n",
    "            im = pyfits.open('../LAURA_Sims/q0.5_fg0.3_allrx10_sunruns/agnx0/broadband_'+str(myr)+'.fits')\n",
    "        \n",
    "        if run=='fg3_m15_iso1':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            im = pyfits.open('../LAURA_Sims/m1_fg0.3_BT0.2_allrx10_isolated_sunruns/broadband_'+prefix+str(myr)+'.fits')\n",
    "        \n",
    "        if run=='fg3_m15':\n",
    "            if myr > 300:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_late/broadband_'+str(myr)+'.fits')\n",
    "            else:\n",
    "                if myr < 10:\n",
    "                    im = pyfits.open('../LAURA_Sims/q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_00'+str(myr)+'.fits')\n",
    "                else:\n",
    "                    if myr < 100:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_0'+str(myr)+'.fits')\n",
    "                    else:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_'+str(myr)+'.fits')\n",
    "        if run=='fg1_m13':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            if myr > 140:\n",
    "                \n",
    "                if myr <360:\n",
    "                    im = pyfits.open('../LAURA_Sims/q0.333_fg0.1_allrx10_sunruns/hires_kin_late/broadband_sdss_z0.03_'+prefix+str(myr)+'.fits')\n",
    "                else:\n",
    "                    im = pyfits.open('../LAURA_Sims/q0.333_fg0.1_allrx10_sunruns/hires_kin_late/broadband_'+prefix+str(myr)+'.fits')\n",
    "            \n",
    "            else:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.333_fg0.1_allrx10_sunruns/hires_kin_early_cen1/broadband_'+prefix+str(myr)+'.fits')\n",
    "            \n",
    "        if run=='fg1_m13_iso1':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            im = pyfits.open('../LAURA_Sims/isolated_galaxies/m1_fg0.1/broadband_'+prefix+str(myr)+'.fits')\n",
    "        if run=='fg1_m13_iso0.333':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            im = pyfits.open('../LAURA_Sims/isolated_galaxies/m0.333_fg0.1/broadband_'+prefix+str(myr)+'.fits')\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            kin_cube=pyfits.open('stellar_kinematics_'+str(adds)+'_'+str(run)+'_'+str(myr)+'_'+str(view)+'.fits')\n",
    "            #kin_cube=pyfits.open('stellar_kinematic_maps_sunrise/stellar_kinematics_NONSCATTER_'+str(myr)+'_'+str(view)+'.fits')\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print('STELLAR velocity map not there yet', 'stellar_kinematics_'+str(adds)+'_'+str(run)+'_'+str(myr)+'_'+str(view)+'.fits')\n",
    "            continue\n",
    "        \n",
    "        dia = np.where(kin_cube[1].data != 0.0)\n",
    "        dia_pix = (dia[1].max()-dia[1].min())#this is the number of pixels\n",
    "        dia = dia_pix*0.5#because 0.5\" per spaxel\n",
    "        \n",
    "        \n",
    "        vel = ma.masked_where(kin_cube[1].data==0, kin_cube[1].data)\n",
    "        vel_e = ma.masked_where(kin_cube[2].data==0, kin_cube[2].data)\n",
    "        sig = ma.masked_where(kin_cube[3].data==0, kin_cube[3].data)\n",
    "        sig_e = ma.masked_where(kin_cube[4].data==0, kin_cube[4].data)\n",
    "        r_band = kin_cube[5].data\n",
    "        r_band = ma.masked_where(r_band>1e10, r_band)\n",
    "        \n",
    "        vel = ma.masked_where(abs(vel)>1000, vel)\n",
    "        vel_e = ma.masked_where(abs(vel)>1000, vel_e)\n",
    "        \n",
    "        \n",
    "        img_params=extract_GALFIT_parameters(view, myr, im, run)\n",
    "        #return PA_img, size_a, arcs_totes, inc, pixelscale, r_e\n",
    "        if img_params[0]==0:\n",
    "            #this means the GALFIT file doesn't exist\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            #I have found the PA from GALFIT to be better than the PA from statmorph \n",
    "            #which is commented out below\n",
    "            PA_imag=img_params[0]\n",
    "        except TypeError:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        epsilon = 1-img_params[1]\n",
    "        r_e = img_params[2]\n",
    "        \n",
    "        #print('deltapos', deltapos)\n",
    "        #continue\n",
    "        \n",
    "        #epsilon = float(kin_cube[0].header['ellip']), again the epsilon from GALFIT is better\n",
    "        #r_e = float(kin_cube[0].header['REFF'])\n",
    "        #PA_img = float(kin_cube[0].header['PA_img']), again, the PA from GALFIT seems to be better\n",
    "        \n",
    "        '''axial ratio (q) = b/a = semi-minor/semi-major\n",
    "        ellipticity () = 1  q'''\n",
    "        \n",
    "        \n",
    "        \n",
    "        #from the r-band image you need to run statmorph and get both the ellipticity and the r-band effective radius\n",
    "        #we already measured this from the r-band image in the kinematic program so I'd like to extract those two \n",
    "        #parameters from the header of the stellar_kinematics file\n",
    "        \n",
    "        \n",
    "        \n",
    "        size=np.shape(vel)[0]\n",
    "        coords=map_to_coords(kin_cube, size)\n",
    "        \n",
    "        rad = radon_python_mod(vel, 30, 30, r_e, 1, 'yes')#was 30,30\n",
    "        if rad[8]==1:#this means we gotta expand the grid\n",
    "            rad = radon_python_mod(vel, 30, 30, r_e, 2, 'yes')\n",
    "        \n",
    "        \n",
    "        \n",
    "        input_kinemetry(run, myr, view, coords[0], coords[1], coords[2], coords[3], coords[4], coords[5] , size/2-rad[0][0], size/2-rad[0][1], adds)\n",
    "        \n",
    "        \n",
    "        continue\n",
    "        \n",
    "        \n",
    "        deltapos = compare_centers(r_band, sig, size/2-rad[0][0], size/2-rad[0][1], z)\n",
    "        \n",
    "        \n",
    "        ang_mom = angular_momentum(vel, sig, r_band, r_e)\n",
    "        \n",
    "        \n",
    "        myr_actual = im['SFRHIST'].header['SNAPTIME']/10**9\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        out_kin=read_kin_maps(r_band, run, myr, view, dia, PA_imag, size, adds, vel, rad[0])\n",
    "        \n",
    "        if out_kin==0:\n",
    "            continue\n",
    "        \n",
    "        if counter==0:\n",
    "            file1.write('Counter'+'\\t'+'Image'+'\\t'+'class label'+'\\t'+'Myr'+'\\t'+'Viewpoint'+'\\t'+'Delta PA'+'\\t'+'v_asym'+'\\t'+'s_asym'+'\\t'+'resids'+'\\t'+'lambda_r'+'\\t'+'epsilon'+'\\t'+'A'+'\\t'+'A_2'+'\\t'+'deltapos'+'\\t'+'deltapos2'+'\\n')#+'i'+'\\t'+'fiber'+'\\n')#was str(np.shape(vel_dist)[1]-1-j)\n",
    "        try:\n",
    "            make_table(counter,run, merger, myr_actual, view, out_kin[0], out_kin[1], out_kin[2], out_kin[4],i, j, ang_mom, epsilon, rad[2],  rad[3], deltapos[0], deltapos[1])#, inclination, fiber[0])\n",
    "        except TypeError:\n",
    "            continue\n",
    "        counter+=1\n",
    "        \n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        \n",
    "        \n",
    "        continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "file1.close()\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
