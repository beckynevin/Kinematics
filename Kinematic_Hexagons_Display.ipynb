{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyfits\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "import matplotlib\n",
    "import math\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion\n",
    "from scipy.ndimage import iterate_structure\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "import scipy.optimize as opt\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from astropy.convolution import convolve\n",
    "from astropy.io import fits\n",
    "import math\n",
    "import photutils\n",
    "import statmorph\n",
    "from skimage import measure\n",
    "from bresenham import bresenham\n",
    "from photutils import CircularAperture,aperture_photometry\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configured\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def fit_2_gaussian(data):\n",
    "    \"\"\"\n",
    "    Fits 2D gaussians to surface brightness using the guesses from the low pass filter of the galaxy locations\n",
    "    Basically, this is my own design of a rough precursor to Source Extractor\n",
    "    \"\"\"\n",
    "    # Create x and y indices\n",
    "    data=np.flipud(data)\n",
    "    x = np.linspace(0, np.shape(data)[0]-1,np.shape(data)[0])\n",
    "    y = np.linspace(0, np.shape(data)[1]-1, np.shape(data)[1])\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.hold(True)\n",
    "    #im = ax.imshow(data, cmap=plt.cm.jet, origin='bottom')\n",
    "    #I haven't figured out how to create contours without also creating a plot\n",
    "    cs = ax.contour(x, y, data, 8, colors='w')\n",
    "    plt.clf()\n",
    "    \n",
    "    p = cs.levels#collections[0].get_paths()[0]\n",
    "    \n",
    "    \n",
    "    #Now, snatch the last level and use it to blur everything else out and find the center with a binary threshold\n",
    "    ret,thresh = cv2.threshold(data,p[-1],2000,cv2.THRESH_BINARY)\n",
    "\n",
    "    M = cv2.moments(thresh)\n",
    "    \n",
    "    \n",
    " \n",
    "    # calculate x,y coordinate of center\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return cX, np.shape(data)[0]-cY\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def compare_centers(image, disp, x_kin, y_kin, z):\n",
    "    \"\"\"\n",
    "    Compares the centeroid of the r-band image to that of the velocity dispersion 2D map,\n",
    "    also to the kinematic center (x_kin,y_kin).\n",
    "    It does this in terms of a physical distance in kpc, given the redshift of the galaxy.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    #Apply a 10x10 kernal to the image to filter out noise (its basically a low pass filter)\n",
    "    #to smooth things out\n",
    "    kernel = np.ones((10,10))\n",
    "\n",
    "    lp = ndimage.convolve(image.filled(fill_value=0), kernel)#was result\n",
    "    \n",
    "    \n",
    "    c=fit_2_gaussian(lp)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    img_cen_x = c[0]\n",
    "    img_cen_y = c[1]\n",
    "    \n",
    "    \n",
    "    #Do this whole thing again but for the velocity dispersion map\n",
    "    kernel = np.ones((10,10))\n",
    "\n",
    "    lp = ndimage.convolve(disp.filled(fill_value=0), kernel)#was result\n",
    "\n",
    "    c=fit_2_gaussian(lp)\n",
    "\n",
    "    disp_cen_x = c[0]\n",
    "    disp_cen_y = c[1]\n",
    "    \n",
    "    \n",
    "    kpc_arcsec=(cosmo.kpc_proper_per_arcmin(z).value/60)\n",
    "    spax_to_kpc = 0.5*kpc_arcsec\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return spax_to_kpc*np.sqrt((img_cen_x-disp_cen_x)**2+(img_cen_y-disp_cen_y)**2), spax_to_kpc*np.sqrt((img_cen_x-x_kin)**2+(img_cen_y-y_kin)**2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def extract_GALFIT_parameters(view, myr, im, run):\n",
    "    \"\"\"\n",
    "    This retrives the GALFIT predictors \n",
    "    \"\"\"\n",
    "    output='../LAURA_Sims/GALFIT_folder/out_'+str(run)+'_'+str(view)+'_'+str(myr)+'.fits'\n",
    "    try:\n",
    "        out=pyfits.open(output)\n",
    "    except FileNotFoundError:\n",
    "        #print('NO GALFIT FILEEEE')\n",
    "        STOP\n",
    "        \n",
    "        return 0, 0, 0\n",
    "\n",
    "    \n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            attempt=float(out[2].header['1_MAG'][0:5])\n",
    "            attempt_2=float(out[2].header['2_MAG'][0:5])\n",
    "        except ValueError:\n",
    "            return 0, 0, 0\n",
    "        if float(out[2].header['1_MAG'][0:5]) < float(out[2].header['2_MAG'][0:5]):\n",
    "        #this means the 1st one is brighter\n",
    "            inc=float(out[2].header['1_AR'][0:5])\n",
    "            r_e=float(out[2].header['1_RE'][0:5])\n",
    "            PA_img=(float(out[2].header['1_PA'][:5]))\n",
    "            \n",
    "        else:\n",
    "            inc=float(out[2].header['2_AR'][0:5])\n",
    "            r_e=float(out[2].header['2_RE'][0:5])\n",
    "            PA_img=(float(out[2].header['2_PA'][:5]))\n",
    "            \n",
    "    except KeyError or ValueError:#if there is no #2\n",
    "        try:\n",
    "            \n",
    "            inc=float(out[2].header['1_AR'][0:5])\n",
    "            r_e=float(out[2].header['1_RE'][0:5])\n",
    "            PA_img=(float(out[2].header['1_PA'][:5]))\n",
    "        except ValueError:\n",
    "            return 0, 0, 0\n",
    "        \n",
    "    return PA_img, inc, r_e\n",
    "\n",
    "\n",
    "def map_to_coords(map_cube, size):\n",
    "    \"\"\"\n",
    "    Converts coordinates to list form (in order to feed through kinemetry).\n",
    "    \"\"\"\n",
    "    x_list=[]\n",
    "    y_list=[]\n",
    "    vel_list=[]\n",
    "    vel_e_list=[]\n",
    "    sig_list=[]\n",
    "    sig_e_list=[]\n",
    "    \n",
    "    vel_dimension=map_cube[1].data\n",
    "    vel_e_dimension=map_cube[2].data\n",
    "    sig_dimension=map_cube[3].data\n",
    "    sig_e_dimension=map_cube[4].data\n",
    "    \n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            try:\n",
    "                value = vel_dimension[i,j]\n",
    "                if str(value) == '--':\n",
    "                    continue\n",
    "                vel_list.append(vel_dimension[i,j])\n",
    "                x_list.append(i)\n",
    "                y_list.append(j)\n",
    "                vel_e_list.append(vel_e_dimension[i,j])\n",
    "                sig_list.append(sig_dimension[i,j])\n",
    "                sig_e_list.append(sig_e_dimension[i,j])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            \n",
    "    \n",
    "    \n",
    "    return x_list, y_list, vel_list, vel_e_list, sig_list, sig_e_list\n",
    "\n",
    "\n",
    "\n",
    "def input_kinemetry(name, myr, view, x_list_after, y_list_after, vel_list_after, vel_e_list_after, sig_list_after, sig_e_list_after,  img_x, img_y, add_on):\n",
    "    \"\"\"\n",
    "    Creates an input file for kinemetry (.txt file) that has columns of x and y coords, velocity, velocity dispersion,\n",
    "    and the errors on both of these values.\n",
    "    \"\"\"\n",
    "    file2=open('kinemetry_input_txt/kinemetry_recenter_'+str(name)+'_'+str(myr)+'_'+str(view)+'.txt','w')\n",
    "    file2.write('#'+'\\t'+'XBIN'+'\\t'+'YBIN'+'\\t'+'VEL'+'\\t'+'ER_VEL'+'\\t'+'SIG'+'\\t'+'ER_SIG'+'\\n')\n",
    "    \n",
    "    #These are the coordinates of the kinematic center of the galaxy\n",
    "    middle_x=img_x\n",
    "    middle_y=img_y\n",
    "    \n",
    "    #for some reason, kinemetry wants each row indexed\n",
    "    counter=1\n",
    "    \n",
    "    for i in range(len(x_list_after)):\n",
    "        if np.isnan(vel_list_after[i]):#mask these values by not including them in the file\n",
    "            continue\n",
    "        if vel_list_after[i]==0.0:#these are also list indices to mask\n",
    "            continue\n",
    "        file2.write(str(counter)+'\\t'+str((middle_x-x_list_after[len(x_list_after)-1-i]))+'\\t'+str((middle_y-y_list_after[len(x_list_after)-1-i]))+'\\t')\n",
    "        file2.write(str(vel_list_after[i])+'\\t'+str(vel_e_list_after[i])+'\\t'+str(sig_list_after[i])+'\\t'+str(sig_e_list_after[i])+'\\n')\n",
    "        counter +=1\n",
    "\n",
    "    file2.close()\n",
    "\n",
    "def read_kin_maps(img, name, myr, view, dia, PA_img, size_cont, add_on, observed_velocity, kincen):\n",
    "   \n",
    "    file_velcirc='kinemetry_solution/myfile_v_'+str(name)+'_'+str(myr)+'_'+str(view)+'.txt'\n",
    "    \n",
    "    stel_vel_model=np.zeros((size,size))\n",
    "    stel_vel_model_tester=np.zeros((size,size))\n",
    "    stel_vel=np.zeros((size,size))\n",
    "    stel_sig_model=np.zeros((size,size))\n",
    "    stel_vel_kin_model=np.zeros((size,size))\n",
    "\n",
    "    try:\n",
    "        with open(file_velcirc, 'r') as f:\n",
    "            data = f.readlines()\n",
    "\n",
    "\n",
    "            x_list_model=[]\n",
    "            y_list_model=[]\n",
    "            vel_circ_model=[]\n",
    "            vel_kin_model=[]\n",
    "            vel_in=[]\n",
    "            vel_in_e=[]\n",
    "            vel_sig_model=[]\n",
    "            vel_kin_model=[]\n",
    "\n",
    "            for line in data:\n",
    "                words = line.split()\n",
    "                #print('words', words)\n",
    "\n",
    "                if words[4]=='*************************':\n",
    "                    continue\n",
    "                else:\n",
    "                    x_list_model.append(float(words[0]))\n",
    "                    y_list_model.append(float(words[1]))\n",
    "                    vel_in.append(float(words[2]))\n",
    "                    vel_in_e.append(float(words[3]))\n",
    "                    vel_circ_model.append(float(words[4]))\n",
    "                    vel_kin_model.append(float(words[5]))\n",
    "\n",
    "\n",
    "                    stel_vel[int(float(words[0])-size/2),int(float(words[1])-size/2)] = float(words[2])\n",
    "                    stel_vel_model[int(float(words[0])-size/2),int(float(words[1])-size/2)] = float(words[4])\n",
    "                    stel_vel_kin_model[int(float(words[0])-size/2),int(float(words[1])-size/2)] = float(words[5])\n",
    "                    #stel_vel_model_tester[int(float(words[1])-size/2),int(float(words[0])-size/2)] = float(words[4])\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "\n",
    "    '''\n",
    "    ~~~~~~~Sigs~~~~~~~\n",
    "    '''\n",
    "    stel_vel_model = ma.masked_where(stel_vel_model ==0, stel_vel_model)\n",
    "    stel_vel_kin_model = ma.masked_where(stel_vel_kin_model ==0, stel_vel_kin_model)\n",
    "    stel_vel = ma.masked_where(stel_vel ==0, stel_vel)\n",
    "    #stel_sig_model=((ma.masked_where(stel_sig_model==0, stel_sig_model)))\n",
    "    '''plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax0=fig.add_subplot(141)\n",
    "    im0 = ax0.imshow(img, cmap='afmhot_r')\n",
    "    plt.colorbar(im0)\n",
    "    ax0.set_title('Imaging', size=10)\n",
    "    \n",
    "    ax1=fig.add_subplot(142)\n",
    "    im1 = ax1.imshow((stel_vel), cmap='RdBu_r', vmin=-100, vmax=100)\n",
    "    plt.xlim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    plt.ylim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    plt.colorbar(im1)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(r'V$_{*}$', size=10)\n",
    "\n",
    "    ax2=fig.add_subplot(143)\n",
    "    im2 = ax2.imshow((stel_vel_model), cmap='RdBu_r', vmin=-100, vmax=100)\n",
    "    plt.xlim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    plt.ylim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    ax2.axis('off')\n",
    "    plt.colorbar(im2)\n",
    "    ax2.set_title(r'V$_{\\mathrm{kinemetry}}$', size=10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax3=fig.add_subplot(144)\n",
    "    im3 = ax3.imshow(((stel_vel - stel_vel_model)/stel_vel_model), cmap='RdBu_r')#, vmin=-100, vmax=100)\n",
    "    plt.xlim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    plt.ylim([size/2-(dia-0.5)/2,size/2+(dia-0.5)/2])\n",
    "    plt.colorbar(im3)\n",
    "    plt.annotate(str(round(resids,1)),xy=(0.05,0.05), xycoords='axes fraction')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    ax3.set_title(r'Velocity Residuals', size=10)\n",
    "    \n",
    "    #plt.colorbar(ax1)\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/velocity_model_compare_'+str(add_on)+'_'+str(myr)+'_'+str(view)+'.pdf',bbox_inches='tight' )\n",
    "    '''\n",
    "    stel_vel_model=ma.masked_where(stel_vel_model > 1000, stel_vel_model)\n",
    "    #stel_vel_model=ma.masked_where(stel_vel_model == 0, stel_vel_model)\n",
    "    \n",
    "    \n",
    "    '''Now open the file with kinematic PA, v_asym, s_asym'''\n",
    "    file_deets='kinemetry_solution/text_out_'+str(name)+'_'+str(myr)+'_'+str(view)+'.txt'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open(file_deets, 'r') as f:\n",
    "            data = f.readlines()\n",
    "            for line in data:\n",
    "                words = line.split()\n",
    "\n",
    "                PA_kin=float(words[0])\n",
    "                PA_kin_e=float(words[1])\n",
    "                v_asym=float(words[2])\n",
    "                s_asym=float(words[3])\n",
    "                K_asym=float(words[4])\n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "    \n",
    "    x=np.linspace(0,size, 1000)\n",
    "    ys_kin=[(j-size_cont/2)/math.tan(math.radians(PA_kin))+size_cont/2 for j in x]\n",
    "    plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax0 = fig.add_subplot(131)\n",
    "    im0 = ax0.imshow(observed_velocity, cmap='RdBu_r')#, vmin=-100, vmax=100)\n",
    "    plt.colorbar(im0, fraction=0.05)\n",
    "    ax0.scatter(np.shape(observed_velocity)[0]/2+kincen[0], np.shape(observed_velocity)[0]/2+kincen[1], color='black', marker='x')\n",
    "    ax0.set_title('$V_{*}$')\n",
    "    ax0.set_xlim([0,np.shape(observed_velocity)[0]])\n",
    "    ax0.set_ylim([0,np.shape(observed_velocity)[1]])\n",
    "    #ax0.axis('off')\n",
    "    \n",
    "    ax1 = fig.add_subplot(132)\n",
    "    im1 = ax1.imshow(stel_vel_model, cmap='RdBu_r')#, vmin=-100, vmax=100)\n",
    "    ax1.scatter(np.shape(observed_velocity)[0]/2+kincen[0], np.shape(observed_velocity)[0]/2+kincen[1], color='black', marker='x')\n",
    "    \n",
    "    ax1.set_xlim([0,np.shape(observed_velocity)[0]])\n",
    "    ax1.set_ylim([0,np.shape(observed_velocity)[1]])\n",
    "    \n",
    "    ax1.plot(x,ys_kin, color='black')\n",
    "    ax1.set_title('$V_{\\mathrm{model}}$')\n",
    "    plt.colorbar(im1, fraction=0.05)\n",
    "    #plt.title(r'\\texttt{kinemetry}')\n",
    "    #ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(133)\n",
    "    observed_mask = ma.masked_where(stel_vel_model==0, observed_velocity)\n",
    "    resids=np.sum(abs(observed_mask - stel_vel_model))/stel_vel_model.count()#np.mean(abs((stel_vel - stel_vel_model)/stel_vel_model))\n",
    "    #print('these are the resids', resids, 'n_spaxels', stel_vel_model.count())\n",
    "    im2 = ax2.imshow((observed_mask - stel_vel_model),  cmap='RdBu_r', vmin=-50, vmax=50)\n",
    "    ax2.scatter(np.shape(observed_velocity)[0]/2+kincen[0], np.shape(observed_velocity)[0]/2+kincen[1], color='black', marker='x')\n",
    "    \n",
    "    ax2.set_title('$V_{*} - V_{\\mathrm{model}}$')\n",
    "    plt.colorbar(im2, fraction=0.05)\n",
    "    ax2.set_xlim([0,np.shape(observed_velocity)[0]])\n",
    "    ax2.set_ylim([0,np.shape(observed_velocity)[1]])\n",
    "    #ax2.axis('off')\n",
    "    ax2.annotate('Residuals = '+str(round(resids,2)), xy=(0.05,0.85), xycoords='axes fraction')\n",
    "    \n",
    "    '''ax3 = fig.add_subplot(224)\n",
    "    im3 = ax3.imshow(abs(observed_mask - stel_vel_model),  norm=matplotlib.colors.LogNorm(),cmap='magma')\n",
    "    ax3.set_title('|$V_{*} - V_{\\mathrm{model}}$|')\n",
    "    plt.colorbar(im3, fraction=0.1)\n",
    "    \n",
    "    ax3.set_xlim([0,np.shape(observed_velocity)[0]])\n",
    "    ax3.set_ylim([0,np.shape(observed_velocity)[1]])\n",
    "    \n",
    "    ax3.axis('off')'''\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('kinemetry_result_'+str(name)+'_'+str(myr)+'_'+str(view)+'.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''PA_kin is measured from the south CCW, so -115 is actually 115 degrees to the CW direction from south'''\n",
    "    '''PA_imag is measured from the north CCW as well (argh)'''\n",
    "    PA_kin_moved = PA_kin#was 180+PA_kin\n",
    "    PA_img_moved = PA_img\n",
    "    \n",
    "    '''if abs(PA_img_moved-PA_kin_moved) > 90 and abs(PA_img_moved-PA_kin_moved) < 180:\n",
    "        new_delta_PA = 180-abs(PA_img_moved-PA_kin_moved)\n",
    "    else:\n",
    "        new_delta_PA = abs(PA_img_moved-PA_kin_moved)\n",
    "    if abs(PA_img_moved-PA_kin_moved) > 180:\n",
    "        new_delta_PA = abs(PA_img_moved-PA_kin_moved)-180'''\n",
    "    \n",
    "    new_delta_PA = abs(PA_img_moved-PA_kin_moved)\n",
    "    \n",
    "    \n",
    "    return new_delta_PA, v_asym, s_asym, K_asym, resids\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def make_table(counter, image, merger, myr, view, dPA, v_a, s_a,  resids, i, j, lambdar, epsilon, A,  A_2, dpos, dpos2):\n",
    "    #make_table(myr, view, out_kin[0], out_kin[1], out_kin[2], out_kin[3], out_kin[4])\n",
    "    if dPA > 90:\n",
    "        dPA = 180-dPA\n",
    "    file1.write(str(counter)+'\\t'+str(image)+'\\t'+str(merger)+'\\t'+str(round(myr,2))+'\\t'+str(view)+'\\t'+str(round(dPA,2))+'\\t'+str(round(v_a,2))+\n",
    "                    '\\t'+str(round(s_a,2))+'\\t'+str(round(resids,2))+'\\t'+\n",
    "                str(round(lambdar,2))+'\\t'+str(round(epsilon,2))+'\\t'+str(round(A,2))+'\\t'+str(round(A_2,2))+'\\t'+str(round(dpos,2))+'\\t'+str(round(dpos2,2))+'\\n')#was str(np.shape(vel_dist)[1]-1-j)\n",
    "    \n",
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def angular_momentum(velocity, dispersion, r_band, r_e):\n",
    "    #lambda_r_e = f*r*|v|/f*r*(v**2+sig**2)^(1/2)\n",
    "    #step 1 is to determine the effective radius in the r-band, which is from the full broadband image\n",
    "    #so the effective radius is in spaxels here (I think?) so just mask if sqrt(x_dist**2+y_dist**2)\n",
    "    #is greater than this amount\n",
    "    middle = np.shape(velocity)[0]/2\n",
    "    #print('middle', middle)\n",
    "    num=[]\n",
    "    denom=[]\n",
    "    for x in range(np.shape(velocity)[0]):\n",
    "        for y in range(np.shape(velocity)[1]):\n",
    "            distance_from_center = np.sqrt((x - middle)**2 + (y-middle)**2)\n",
    "            #print('distance', distance_from_center)\n",
    "            if distance_from_center > r_e:\n",
    "                continue\n",
    "            else:\n",
    "                num.append((r_band[x,y]*distance_from_center*abs(velocity[x,y])))\n",
    "                denom.append((r_band[x,y]*distance_from_center*np.sqrt(velocity[x,y]**2+dispersion[x,y]**2)))\n",
    "                #print('num', (r_band[x,y]*distance_from_center*abs(velocity[x,y])))\n",
    "                #print('denom',(r_band[x,y]*distance_from_center*np.sqrt(velocity[x,y]**2+dispersion[x,y]**2)))\n",
    "    #print('num', num)\n",
    "    #print('denom', denom)\n",
    "    \n",
    "    #print(np.nansum(num))\n",
    "    #print(np.nansum(denom))\n",
    "    lambdar = np.nansum(num)/np.nansum(denom)   \n",
    "    #print('lambdar', lambdar)\n",
    "    #summed_lambda = np.sum(lambdar)\n",
    "    return lambdar\n",
    "def ndim_grid(start,stop):\n",
    "    # Set number of dimensions\n",
    "    ndims = len(start)\n",
    "\n",
    "    # List of ranges across all dimensions\n",
    "    L = [np.arange(start[i],stop[i]) for i in range(ndims)]\n",
    "\n",
    "    # Finally use meshgrid to form all combinations corresponding to all \n",
    "    # dimensions and stack them as M x ndims array\n",
    "    return np.hstack((np.meshgrid(*L))).swapaxes(0,1).reshape(ndims,-1).T\n",
    "\n",
    "def radon_python_mod(vel_field, n_p, n_theta, r_ap, factor):\n",
    "    \"\"\"\n",
    "    This section performs the radon transform, from Stark et al. 2018\n",
    "    \n",
    "    \"\"\"\n",
    "    #It first converts the x and y coordinates into p and theta coordinates (circular)\n",
    "    p_list = np.linspace(-int(np.shape(vel_field)[0]/2)+5,int(np.shape(vel_field)[0]/2)-5, int(np.shape(vel_field)[0]/2)+1)#was 5\n",
    "    p_list = np.linspace(-int(np.shape(vel_field)[0]/2)+5, int(np.shape(vel_field)[0]/2)-5,n_p)#was 20\n",
    "   \n",
    "    \n",
    "    theta_list = np.linspace(0, 180, n_theta)#was 10\n",
    "    \n",
    "    #It searches over a grid of coordinates around the photometric center to find the 'kinematic center',\n",
    "    #which is the coordinate where A is minimized, which is the asymmetry of the Radon profile constructed\n",
    "    #from R_AB, which is the Absolute Radon Transform.\n",
    "    box_list=list(ndim_grid([-3, -3],[4,4]))\n",
    "    #If the kinematic center is not found on the first iteration, it expands the dimensions of the grid\n",
    "    #by a factor of 2.\n",
    "    box_list=[factor*x for x in box_list]\n",
    "    \n",
    "    X_list=[]\n",
    "    Y_list=[]\n",
    "    c_list=[]\n",
    "    for j in range(len(box_list)):\n",
    "        \n",
    "        X_list.append(int(np.shape(vel_field)[0]/2+box_list[j][0]))#-10+box_list[b][0])\n",
    "        Y_list.append(int(np.shape(vel_field)[1]/2+box_list[j][1]))#-10+box_list[b][1])\n",
    "        c_list.append(j)\n",
    "    \n",
    "    \n",
    "    A_list=[]\n",
    "    A_e_list=[]\n",
    "    \n",
    "    A_2_list=[]\n",
    "    R_AB_list=[]\n",
    "    theta_hat_list=[]\n",
    "    theta_hat_e_list=[]\n",
    "    \n",
    "    \n",
    "    #First run it for just the center one, index b=24 in order to normalize relative to the center\n",
    "    #later on in the calculation of A.\n",
    "    R_AB=[]\n",
    "    b=24\n",
    "    for i in range(len(p_list)):\n",
    "        for j in range(len(theta_list)):\n",
    "\n",
    "            X = int(p_list[i]*math.cos(math.radians(theta_list[j]))+np.shape(vel_field)[0]/2+box_list[b][0])#-10+box_list[b][0])\n",
    "            Y = int(p_list[i]*math.sin(math.radians(theta_list[j]))+np.shape(vel_field)[1]/2+box_list[b][1])#-10+box_list[b][1])\n",
    "\n",
    "\n",
    "            '''We have an X and a Y and a theta (slope) so we should be able to get the intercept'''\n",
    "            '''And then two more points on either end'''\n",
    "\n",
    "\n",
    "            '''But we only want to calculate for things that are on the circle'''\n",
    "\n",
    "            try:\n",
    "                test_value = vel_field[X,Y]\n",
    "            except IndexError:\n",
    "                R_AB.append(-1000)\n",
    "                \n",
    "\n",
    "                continue\n",
    "            if np.isnan(vel_field[X,Y]):\n",
    "                #print('nan', 'outside')\n",
    "                R_AB.append(-1000)\n",
    "                \n",
    "\n",
    "                continue\n",
    "\n",
    "            if str(vel_field[X,Y]) == '--':\n",
    "                #print('--', 'outside')\n",
    "                R_AB.append(-1000)\n",
    "                \n",
    "\n",
    "                continue\n",
    "            deltay = Y - np.shape(vel_field)[1]/2\n",
    "            deltax = X - np.shape(vel_field)[0]/2\n",
    "\n",
    "\n",
    "            '''Now draw a line perpendicular to this'''\n",
    "            slope_p = math.tan(math.radians(theta_list[j]+90))#-deltax/deltay\n",
    "\n",
    "            intercept = Y - slope_p*X\n",
    "\n",
    "\n",
    "\n",
    "            if slope_p > 1000:\n",
    "                x_min = X\n",
    "                x_max = X\n",
    "                y_min = 0\n",
    "                y_max = np.shape(vel_field)[0]\n",
    "            else:\n",
    "                x_min = 0\n",
    "                x_max = np.shape(vel_field)[0]\n",
    "                y_min = intercept\n",
    "                y_max = intercept+slope_p*x_max\n",
    "\n",
    "            bres_line = list(bresenham(int(x_min), int(y_min), int(x_max), int(y_max)))\n",
    "\n",
    "            #print(bres_line)\n",
    "            bres_line_new=[]\n",
    "            for k in range(len(bres_line)):\n",
    "\n",
    "                if bres_line[k][1] < 0 or bres_line[k][1]>np.shape(vel_field)[1]:\n",
    "                    continue\n",
    "                else:\n",
    "                    bres_line_new.append(bres_line[k])\n",
    "\n",
    "            bres_list=bres_line_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            vel_append=[]\n",
    "            #vel_new=np.zeros((np.shape(vel_field)[0], np.shape(vel_field)[1]))\n",
    "            for k in range(len(bres_list)):\n",
    "                if bres_list[k][0] < 0 or bres_list[k][1] < 0:\n",
    "                    continue\n",
    "                #plt.scatter(bres_list[k][0], bres_list[k][1], color='yellow')\n",
    "\n",
    "                try:\n",
    "                    #print('now going to append', vel_field[bres_list[j][1], bres_list[j][0]])\n",
    "\n",
    "                    if ma.is_masked(vel_field[bres_list[k][1], bres_list[k][0]]):\n",
    "                        continue\n",
    "                    else:\n",
    "                        vel_append.append(vel_field[bres_list[k][1], bres_list[k][0]])\n",
    "                        \n",
    "                    #vel_new[bres_list[j][1], bres_list[j][0]] = vel_field[bres_list[j][1], bres_list[j][0]]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "\n",
    "            inside=vel_append-np.mean(vel_append)\n",
    "            \n",
    "            vel_append=[]\n",
    "            for k in range(len(bres_list)):\n",
    "                if bres_list[k][0] < 0 or bres_list[k][1] < 0:\n",
    "                    continue\n",
    "                if np.sqrt((bres_list[k][0]-X)**2+(bres_list[k][1]-Y)**2) > r_e/2:\n",
    "                    continue\n",
    "               \n",
    "                try:\n",
    "                    vel_append.append(vel_field[bres_list[k][1], bres_list[k][0]])\n",
    "                    #vel_new[bres_list[j][1], bres_list[j][0]] = vel_field[bres_list[j][1], bres_list[j][0]]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "            vel_append_clean=[]\n",
    "            for k in range(len(vel_append)):\n",
    "                if ma.is_masked(vel_append[k]):\n",
    "                    continue\n",
    "                else:\n",
    "                    vel_append_clean.append(vel_append[k])\n",
    "\n",
    "\n",
    "\n",
    "            if vel_append_clean:\n",
    "\n",
    "\n",
    "                inside=vel_append_clean-np.mean(vel_append_clean)\n",
    "                R_AB.append(np.sum(np.abs(inside)))\n",
    "            else:\n",
    "                R_AB.append(-1000)\n",
    "\n",
    "\n",
    "    R_AB=ma.masked_where(np.isnan(R_AB), R_AB)\n",
    "    R_AB = ma.masked_where(R_AB==-1000, R_AB)\n",
    "\n",
    "    R_AB_array = np.reshape(R_AB, (len(p_list),len(theta_list)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    theta_hat=[]\n",
    "    theta_hat_e=[]\n",
    "\n",
    "    for l in range(len(p_list)):\n",
    "\n",
    "        marginalized = R_AB_array[l,:]\n",
    "        #count up how many elements are in the row of R_AB --> if it is less than 4, don't measure it\n",
    "        count = len([i for i in marginalized if i > 1e-3]) \n",
    "        if count < 4:\n",
    "            theta_hat.append(0)\n",
    "            theta_hat_e.append(0)\n",
    "            continue\n",
    "\n",
    "        if ma.is_masked(marginalized)==True:\n",
    "            theta_hat.append(0)\n",
    "            theta_hat_e.append(0)\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        '''plt.clf()\n",
    "        plt.scatter(theta_list, marginalized)'''\n",
    "\n",
    "\n",
    "        def gauss(x,a,x0,sigma,offset):\n",
    "            return a*exp(-(x-x0)**2/(2*sigma**2))+offset\n",
    "        from scipy.optimize import curve_fit\n",
    "        from scipy import asarray as ar,exp\n",
    "\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            popt,pcov = curve_fit(gauss,theta_list,marginalized,p0=[-abs(np.min(marginalized)-np.max(marginalized)),theta_list[list(marginalized).index(np.min(marginalized))],20,np.mean(marginalized)])\n",
    "            append_value = popt[1]\n",
    "            if np.isinf(pcov[0][0]):\n",
    "                STOP\n",
    "        except RuntimeError or OptimizeError:\n",
    "\n",
    "            theta_list_shifted = theta_list+find_nearest(theta_list,90)\n",
    "            index_1 = list(theta_list).index(find_nearest(theta_list,90))\n",
    "            new_marginalized = np.concatenate((marginalized[index_1:], marginalized[:index_1]))\n",
    "\n",
    "            try:\n",
    "                popt,pcov = curve_fit(gauss,theta_list_shifted,new_marginalized,p0=[-abs(np.min(new_marginalized)-np.max(new_marginalized)),theta_list_shifted[list(new_marginalized).index(np.min(new_marginalized))],20,np.mean(new_marginalized)])\n",
    "                if np.isinf(pcov[0][0]):\n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "                    continue\n",
    "                if popt[1] > 180:\n",
    "                    append_value = popt[1]-180\n",
    "                else:\n",
    "                    append_value = popt[1]\n",
    "\n",
    "            except RuntimeError:\n",
    "\n",
    "\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "\n",
    "                continue\n",
    "\n",
    "        \n",
    "\n",
    "        if (popt[1] - 3*np.sqrt(pcov[1][1])) < 0 or (popt[1] + 3*np.sqrt(pcov[1][1])) > 180:\n",
    "            #then we need to wrap and re-fit\n",
    "            #before was - theta_list = np.linspace(0, 180, n_theta)\n",
    "            theta_list_shifted = theta_list+find_nearest(theta_list,90)\n",
    "            index_1 = list(theta_list).index(find_nearest(theta_list,90))\n",
    "            new_marginalized = np.concatenate((marginalized[index_1:], marginalized[:index_1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                popt,pcov = curve_fit(gauss,theta_list_shifted,new_marginalized,p0=[-abs(np.min(new_marginalized)-np.max(new_marginalized)),theta_list_shifted[list(new_marginalized).index(np.min(new_marginalized))],20,np.mean(new_marginalized)])\n",
    "                if np.isinf(pcov[0][0]):\n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "                    continue\n",
    "                    \n",
    "                if popt[1] > 180:\n",
    "                    append_value = popt[1]-180\n",
    "                else:\n",
    "                    append_value = popt[1]\n",
    "\n",
    "            except RuntimeError:\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "                continue\n",
    "        theta_hat.append(append_value)\n",
    "        theta_hat_e.append(np.sqrt(pcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "    #p_list_masked=ma.masked_where(theta_hat < 0, p_list)\n",
    "    #print(p_list)\n",
    "\n",
    "    #print(p_list[0:int(len(p_list)/2)])\n",
    "\n",
    "    delta_theta_sum=[]\n",
    "    delta_theta_sum_e=[]\n",
    "\n",
    "\n",
    "    for l in range(int(len(p_list)/2)):\n",
    "        if (theta_hat[0+l]==0) or (theta_hat[-1-l]==0) or (abs(theta_hat[0+l])>180) or (abs(theta_hat[-1-l]) > 180):\n",
    "\n",
    "            delta_theta_sum.append(0)\n",
    "            delta_theta_sum_e.append(0)\n",
    "        else:\n",
    "\n",
    "\n",
    "            if abs(theta_hat[0+l]-theta_hat[-1-l]) > 90:\n",
    "                #because the maximum you can be apart is 90\n",
    "                inside = 180 - abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "            else:\n",
    "                inside = abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "\n",
    "            delta_theta_sum.append(inside)\n",
    "            delta_theta_sum_e.append(np.sqrt((theta_hat_e[0+l])**2+\n",
    "                                         (theta_hat_e[-1-l])**2))\n",
    "    \n",
    "\n",
    "    theta_hat_mask = ma.masked_where(theta_hat==0, theta_hat)\n",
    "    theta_hat_mask = ma.masked_where(abs(theta_hat_mask) >180, theta_hat_mask)\n",
    "\n",
    "    theta_hat_list.append(theta_hat_mask)\n",
    "    theta_hat_e_list.append(theta_hat_e)\n",
    "\n",
    "    delta_theta_sum_masked=ma.masked_where(np.array(delta_theta_sum)==0, delta_theta_sum)\n",
    "\n",
    "    \n",
    "\n",
    "    OG_weight=ma.count(delta_theta_sum_masked)\n",
    "\n",
    "   \n",
    "    print('onto the main party')\n",
    "    \n",
    "    plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax0 = fig.add_subplot(111)\n",
    "    im0 = ax0.imshow(vel_field, cmap='RdBu_r')\n",
    "    \n",
    "    \n",
    "    #Okay now do this for all the other positions in box_list\n",
    "    A_list=[]\n",
    "    A_e_list=[]\n",
    "    \n",
    "    A_2_list=[]\n",
    "    R_AB_list=[]\n",
    "    theta_hat_list=[]\n",
    "    theta_hat_e_list=[]\n",
    "\n",
    "    for b in range(len(box_list)):\n",
    "        \n",
    "        '''R=[]\n",
    "        R_A=[]'''\n",
    "        R_AB=[]\n",
    "\n",
    "        for i in range(len(p_list)):\n",
    "            for j in range(len(theta_list)):\n",
    "\n",
    "                X = int(p_list[i]*math.cos(math.radians(theta_list[j]))+np.shape(vel_field)[0]/2+box_list[b][0])#-10+box_list[b][0])\n",
    "                Y = int(p_list[i]*math.sin(math.radians(theta_list[j]))+np.shape(vel_field)[1]/2+box_list[b][1])#-10+box_list[b][1])\n",
    "                \n",
    "\n",
    "                '''We have an X and a Y and a theta (slope) so we should be able to get the intercept'''\n",
    "                '''And then two more points on either end'''\n",
    "\n",
    "\n",
    "                '''But we only want to calculate for things that are on the circle'''\n",
    "                \n",
    "                try:\n",
    "                    test_value = vel_field[X,Y]\n",
    "                except IndexError:\n",
    "                    R_AB.append(-1000)\n",
    "                    \n",
    "\n",
    "                    continue\n",
    "                if np.isnan(vel_field[X,Y]):\n",
    "                    #print('nan', 'outside')\n",
    "                    R_AB.append(-1000)\n",
    "                    \n",
    "\n",
    "                    continue\n",
    "\n",
    "                if str(vel_field[X,Y]) == '--':\n",
    "                    #print('--', 'outside')\n",
    "                    R_AB.append(-1000)\n",
    "                    \n",
    "\n",
    "                    continue\n",
    "                deltay = Y - np.shape(vel_field)[1]/2\n",
    "                deltax = X - np.shape(vel_field)[0]/2\n",
    "\n",
    "\n",
    "                '''Now draw a line perpendicular to this'''\n",
    "                slope_p = math.tan(math.radians(theta_list[j]+90))#-deltax/deltay\n",
    "\n",
    "                intercept = Y - slope_p*X\n",
    "\n",
    "\n",
    "\n",
    "                if slope_p > 1000:\n",
    "                    x_min = X\n",
    "                    x_max = X\n",
    "                    y_min = 0\n",
    "                    y_max = np.shape(vel_field)[0]\n",
    "                else:\n",
    "                    x_min = 0\n",
    "                    x_max = np.shape(vel_field)[0]\n",
    "                    y_min = intercept\n",
    "                    y_max = intercept+slope_p*x_max\n",
    "\n",
    "                bres_line = list(bresenham(int(x_min), int(y_min), int(x_max), int(y_max)))\n",
    "\n",
    "                #print(bres_line)\n",
    "                bres_line_new=[]\n",
    "                for k in range(len(bres_line)):\n",
    "\n",
    "                    if bres_line[k][1] < 0 or bres_line[k][1]>np.shape(vel_field)[1]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        bres_line_new.append(bres_line[k])\n",
    "\n",
    "                bres_list=bres_line_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                vel_append=[]\n",
    "                #vel_new=np.zeros((np.shape(vel_field)[0], np.shape(vel_field)[1]))\n",
    "                for k in range(len(bres_list)):\n",
    "                    if bres_list[k][0] < 0 or bres_list[k][1] < 0:\n",
    "                        continue\n",
    "                    #plt.scatter(bres_list[k][0], bres_list[k][1], color='yellow')\n",
    "\n",
    "                    try:\n",
    "                        #print('now going to append', vel_field[bres_list[j][1], bres_list[j][0]])\n",
    "\n",
    "                        if ma.is_masked(vel_field[bres_list[k][1], bres_list[k][0]]):\n",
    "                            continue\n",
    "                        else:\n",
    "                            vel_append.append(vel_field[bres_list[k][1], bres_list[k][0]])\n",
    "                            #if box_list[b][0]==0 and box_list[b][1]==0:\n",
    "                            #    plt.scatter(bres_list[k][0], bres_list[k][1], color='yellow')\n",
    "\n",
    "                        #vel_new[bres_list[j][1], bres_list[j][0]] = vel_field[bres_list[j][1], bres_list[j][0]]\n",
    "                    except IndexError:\n",
    "                        continue\n",
    "\n",
    "                \n",
    "                inside=vel_append-np.mean(vel_append)\n",
    "                '''R_A.append(np.sum(np.abs(inside)))'''\n",
    "\n",
    "\n",
    "\n",
    "                '''R_AB is integrated over a smaller length'''\n",
    "                vel_append=[]\n",
    "                for k in range(len(bres_list)):\n",
    "                    if bres_list[k][0] < 0 or bres_list[k][1] < 0:\n",
    "                        continue\n",
    "                    if np.sqrt((bres_list[k][0]-X)**2+(bres_list[k][1]-Y)**2) > r_e/2:\n",
    "                        continue\n",
    "                    '''if box_list[b][0]==0 and box_list[b][1]==0:\n",
    "                        plt.scatter(bres_list[j][0], bres_list[j][1], color='yellow')'''\n",
    "                    try:\n",
    "                        vel_append.append(vel_field[bres_list[k][1], bres_list[k][0]])\n",
    "                        #vel_new[bres_list[j][1], bres_list[j][0]] = vel_field[bres_list[j][1], bres_list[j][0]]\n",
    "                    except IndexError:\n",
    "                        continue\n",
    "                        \n",
    "                    \n",
    "                        \n",
    "\n",
    "                vel_append_clean=[]\n",
    "                for k in range(len(vel_append)):\n",
    "                    if ma.is_masked(vel_append[k]):\n",
    "                        continue\n",
    "                    else:\n",
    "                        vel_append_clean.append(vel_append[k])\n",
    "\n",
    "                \n",
    "                    \n",
    "                \n",
    "                if vel_append_clean:\n",
    "\n",
    "\n",
    "                    inside=vel_append_clean-np.mean(vel_append_clean)\n",
    "                    R_AB.append(np.sum(np.abs(inside)))\n",
    "                else:\n",
    "                    R_AB.append(-1000)\n",
    "\n",
    "        \n",
    "        R_AB=ma.masked_where(np.isnan(R_AB), R_AB)\n",
    "        R_AB = ma.masked_where(R_AB==-1000, R_AB)\n",
    "        \n",
    "        R_AB_array = np.reshape(R_AB, (len(p_list),len(theta_list)))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        theta_hat=[]\n",
    "        theta_hat_e=[]\n",
    "\n",
    "        for l in range(len(p_list)):\n",
    "\n",
    "            marginalized = R_AB_array[l,:]\n",
    "            count = len([i for i in marginalized if i > 1e-3]) \n",
    "            if count < 4:\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "                continue\n",
    "            #print(type(marginalized))\n",
    "            #print(marginalized)\n",
    "\n",
    "            if ma.is_masked(marginalized)==True:\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            '''plt.clf()\n",
    "            plt.scatter(theta_list, marginalized)'''\n",
    "\n",
    "\n",
    "            def gauss(x,a,x0,sigma,offset):\n",
    "                return a*exp(-(x-x0)**2/(2*sigma**2))+offset\n",
    "            from scipy.optimize import curve_fit\n",
    "            from scipy import asarray as ar,exp\n",
    "\n",
    "            try:\n",
    "                popt,pcov = curve_fit(gauss,theta_list,marginalized,p0=[-abs(np.min(marginalized)-np.max(marginalized)),theta_list[list(marginalized).index(np.min(marginalized))],20,np.mean(marginalized)])\n",
    "                if np.isinf(pcov[0][0]):\n",
    "                    STOP\n",
    "                append_value = popt[1]\n",
    "            except RuntimeError:\n",
    "                \n",
    "                theta_list_shifted = theta_list+find_nearest(theta_list,90)\n",
    "                index_1 = list(theta_list).index(find_nearest(theta_list,90))\n",
    "                new_marginalized = np.concatenate((marginalized[index_1:], marginalized[:index_1]))\n",
    "                \n",
    "                try:\n",
    "                    popt,pcov = curve_fit(gauss,theta_list_shifted,new_marginalized,p0=[-abs(np.min(new_marginalized)-np.max(new_marginalized)),theta_list_shifted[list(new_marginalized).index(np.min(new_marginalized))],20,np.mean(new_marginalized)])\n",
    "                    if np.isinf(pcov[0][0]):\n",
    "                        theta_hat.append(0)\n",
    "                        theta_hat_e.append(0)\n",
    "                        continue\n",
    "                    if popt[1] > 180:\n",
    "                        append_value = popt[1]-180\n",
    "                    else:\n",
    "                        append_value = popt[1]\n",
    "                    \n",
    "                except RuntimeError:\n",
    "                \n",
    "                \n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "\n",
    "                    continue\n",
    "            \n",
    "            '''if abs(np.sqrt(pcov[1][1])/popt[1]) > 1:\n",
    "                theta_hat.append(0)\n",
    "                theta_hat_e.append(0)\n",
    "                continue'''\n",
    "            \n",
    "            if (popt[1] - 3*np.sqrt(pcov[1][1])) < 0 or (popt[1] + 3*np.sqrt(pcov[1][1])) > 180:\n",
    "                #then we need to wrap and re-fit\n",
    "                #before was - theta_list = np.linspace(0, 180, n_theta)\n",
    "                theta_list_shifted = theta_list+find_nearest(theta_list,90)\n",
    "                index_1 = list(theta_list).index(find_nearest(theta_list,90))\n",
    "                new_marginalized = np.concatenate((marginalized[index_1:], marginalized[:index_1]))\n",
    "                \n",
    "                \n",
    "                \n",
    "                    \n",
    "                try:\n",
    "                    popt,pcov = curve_fit(gauss,theta_list_shifted,new_marginalized,p0=[-abs(np.min(new_marginalized)-np.max(new_marginalized)),theta_list_shifted[list(new_marginalized).index(np.min(new_marginalized))],20,np.mean(new_marginalized)])\n",
    "                    if np.isinf(pcov[0][0]):\n",
    "                        theta_hat.append(0)\n",
    "                        theta_hat_e.append(0)\n",
    "                        continue\n",
    "                        '''plt.clf()\n",
    "                        plt.scatter(theta_list_shifted, new_marginalized)\n",
    "                        plt.plot(theta_list_shifted, gauss(theta_list_shifted,*popt))\n",
    "                        plt.show()\n",
    "                        count = len([i for i in new_marginalized if i > 1e-3]) \n",
    "                        print(count)\n",
    "                        print(pcov)\n",
    "                        plt.clf()\n",
    "                        plt.imshow(np.reshape(R_AB, (len(p_list),len(theta_list))), cmap='RdYlBu')#/np.max(R_AB)\n",
    "                        plt.colorbar()\n",
    "                        #plt.xticks([0,len(theta_list)/2,len(theta_list)], [0,90,180])\n",
    "                        #plt.yticks([0, len(p_list)/2, len(p_list)], [p_list[0],0, p_list[-1]])\n",
    "                        plt.xlabel(r'$\\theta$ (degrees)')\n",
    "                        plt.ylabel(r'p')\n",
    "                        plt.title('R_AB')\n",
    "                        index_theta = list(theta_list).index(find_nearest(theta_list,popt[1]))\n",
    "                        plt.scatter(index_theta,l, marker='x', color='black' )\n",
    "                        plt.show()\n",
    "                        print(popt)'''\n",
    "                        \n",
    "                        \n",
    "                    if popt[1] > 180:\n",
    "                        append_value = popt[1]-180\n",
    "                    else:\n",
    "                        append_value = popt[1]\n",
    "                        \n",
    "                except RuntimeError:\n",
    "                    theta_hat.append(0)\n",
    "                    theta_hat_e.append(0)\n",
    "                    continue\n",
    "            theta_hat.append(append_value)\n",
    "            theta_hat_e.append(np.sqrt(pcov[1][1]))\n",
    "            \n",
    "        \n",
    "\n",
    "        #p_list_masked=ma.masked_where(theta_hat < 0, p_list)\n",
    "        #print(p_list)\n",
    "\n",
    "        #print(p_list[0:int(len(p_list)/2)])\n",
    "\n",
    "        delta_theta_sum=[]\n",
    "        delta_theta_sum_e=[]\n",
    "        \n",
    "        \n",
    "        for l in range(int(len(p_list)/2)):\n",
    "            if (theta_hat[0+l]==0) or (theta_hat[-1-l]==0) or (abs(theta_hat[0+l])>180) or (abs(theta_hat[-1-l]) > 180):\n",
    "                \n",
    "                delta_theta_sum.append(0)\n",
    "                delta_theta_sum_e.append(0)\n",
    "            else:\n",
    "                \n",
    "                \n",
    "                if abs(theta_hat[0+l]-theta_hat[-1-l]) > 90:\n",
    "                    #because the maximum you can be apart is 90\n",
    "                    inside = 180 - abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "                else:\n",
    "                    inside = abs(theta_hat[0+l]-theta_hat[-1-l])\n",
    "                \n",
    "                delta_theta_sum.append(inside)\n",
    "                delta_theta_sum_e.append(np.sqrt((theta_hat_e[0+l])**2+\n",
    "                                             (theta_hat_e[-1-l])**2))\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "        theta_hat_mask = ma.masked_where(theta_hat==0, theta_hat)\n",
    "        theta_hat_mask = ma.masked_where(abs(theta_hat_mask) >180, theta_hat_mask)\n",
    "        \n",
    "        theta_hat_list.append(theta_hat_mask)\n",
    "        theta_hat_e_list.append(theta_hat_e)\n",
    "        \n",
    "        delta_theta_sum_masked=ma.masked_where(np.array(delta_theta_sum)==0, delta_theta_sum)\n",
    "\n",
    "        '''print('delta theta sum masked', delta_theta_sum_masked)\n",
    "        print('error on that', delta_theta_sum_e)'''\n",
    "        \n",
    "\n",
    "        A = ((ma.sum(delta_theta_sum)/(ma.count(delta_theta_sum_masked)**2)))*OG_weight\n",
    "       \n",
    "        A_percent_e = []\n",
    "        for l in range(len(delta_theta_sum_e)):\n",
    "            if delta_theta_sum[l] != 0 :\n",
    "                A_percent_e.append((delta_theta_sum_e[l])**2)\n",
    "        A_abs_error = np.sqrt(np.sum(A_percent_e))#so this is on the numerator of A only\n",
    "        A_error = (A_abs_error/ma.sum(delta_theta_sum))*A\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(A)\n",
    "        A_list.append(A)\n",
    "        A_e_list.append(A_error)\n",
    "\n",
    "        '''Also calculate the other types of asymmetry'''\n",
    "        delta_theta_sum=ma.masked_where(np.array(delta_theta_sum)==0, delta_theta_sum)\n",
    "        delta_theta_sum_e=ma.masked_where(np.array(delta_theta_sum_e)==0, delta_theta_sum_e)\n",
    "        theta_hat=ma.masked_where(np.array(theta_hat)==0, theta_hat)\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "        #print('delta_theta_sum', delta_theta_sum)\n",
    "        #print('delta_theta_sum_e', delta_theta_sum_e)\n",
    "        \n",
    "        A_2 = ma.sum(delta_theta_sum/delta_theta_sum_e)\n",
    "        \n",
    "        \n",
    "        \n",
    "        A_2_list.append(A_2)\n",
    "        '''R_list.append(R_array)\n",
    "        R_A_list.append(R_A_array)'''\n",
    "        R_AB_list.append(R_AB_array)\n",
    "        \n",
    "    im1 = ax0.scatter(X_list,Y_list,c=A_list, s=10)\n",
    "    plt.colorbar(im0)  \n",
    "    \n",
    "    \n",
    "    A_list = np.array(A_list)\n",
    "    A_list = ma.masked_where(np.isnan(A_list), A_list)\n",
    "    \n",
    "    min_index = list(A_list).index(A_list.min())\n",
    "    \n",
    "    X_here = (int(np.shape(vel_field)[0]/2+box_list[min_index][0]))#-10+box_list[b][0])\n",
    "    Y_here = (int(np.shape(vel_field)[1]/2+box_list[min_index][1]))#-10+box_list[b][1])\n",
    "    '''plt.scatter(X_here,Y_here, marker='x', color='orange')\n",
    "    \n",
    "    plt.show() \n",
    "    \n",
    "    print('box list order', box_list, 'min', box_list[min_index], 'zeros', box_list[24], 'min index', min_index)\n",
    "    print('X_list', X_list)\n",
    "    print('Y_list', Y_list)\n",
    "    print('A list ordering', A_list, 'min', A_list[min_index])\n",
    "    print('A error', A_e_list, 'min error', A_e_list[min_index])'''\n",
    "    \n",
    "    \n",
    "    A_list_array = np.reshape(np.array(A_list), (7,7))\n",
    "    A_e_list_array = np.reshape(np.array(A_e_list), (7,7))\n",
    "\n",
    "    A_list_array = A_list_array - A_e_list_array\n",
    "    '''plt.clf()\n",
    "    plt.scatter(X_list,Y_list,c=A_list)\n",
    "    plt.colorbar()\n",
    "    plt.show()'''\n",
    "\n",
    "    x = np.linspace(0, np.shape(A_list_array)[0]-1,np.shape(A_list_array)[0])+30\n",
    "    y = (6-np.linspace(0, np.shape(A_list_array)[1]-1, np.shape(A_list_array)[1]))+30\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    '''plt.clf()\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.hold(True)\n",
    "    #im = ax.imshow(data, cmap=plt.cm.jet, origin='bottom')#\n",
    "    im1 = plt.imshow(np.rot90(A_list_array))'''\n",
    "    cs = ax0.contour(x,y, np.rot90(A_list_array), 20, colors='orange')#was 5\n",
    "    '''plt.colorbar(im1)\n",
    "    plt.show()\n",
    "    plt.clf()'''\n",
    "\n",
    "    p = cs.levels#collections[0].get_paths()[0]\n",
    "\n",
    "\n",
    "    '''Now, snatch the last level and use it to blur everything else out and find the center'''\n",
    "\n",
    "\n",
    "    '''now fill with zeros and do your best to turn into a binary bitmask'''\n",
    "    ret,thresh = cv2.threshold(np.rot90(A_list_array),p[0],1,cv2.THRESH_BINARY)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    M = cv2.moments(thresh)\n",
    "\n",
    "\n",
    "\n",
    "    # calculate x,y coordinate of center\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "    \n",
    "    plt.scatter(cX+30,(6-cY)+30, marker='x', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    plt.imshow(thresh)\n",
    "    plt.scatter(cX,(6-cY), marker='x', color='red')\n",
    "    \n",
    "    plt.show()\n",
    "    STOP\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_match = cX+30\n",
    "    y_match = (6-cY)+30\n",
    "    \n",
    "    '''now find the min index of this'''\n",
    "    for ii in range(len(X_list)):\n",
    "        if X_list[ii]==x_match and Y_list[ii]==y_match:\n",
    "            min_index = ii\n",
    "        \n",
    "    '''STOP\n",
    "    \n",
    "    bs = np.linspace(0, len(A_list)-1, len(A_list))\n",
    "    plt.clf()\n",
    "    plt.plot(bs, A_list)\n",
    "    plt.errorbar(bs, A_list, yerr=A_e_list)\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Asymmetry')\n",
    "    plt.ylim([min(A_list)-1, max(A_list)+1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(p_list,theta_hat_list[min_index])\n",
    "    plt.errorbar(p_list,theta_hat_list[min_index], yerr = theta_hat_e_list[min_index])\n",
    "    plt.axvline(x=0)\n",
    "    plt.title('Minimum place R_AB = '+str(A_list[min_index])+' pm '+str(A_e_list[min_index]))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.imshow(R_AB_list[min_index])\n",
    "    plt.title('R_AB min')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.scatter(p_list,theta_hat_list[24])\n",
    "    plt.errorbar(p_list,theta_hat_list[24], yerr = theta_hat_e_list[24])\n",
    "    plt.axvline(x=0)\n",
    "    plt.title('zeros R_AB = '+str(A_list[24])+' pm '+str(A_e_list[24]))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.imshow(R_AB_list[24])\n",
    "    plt.title('R_AB zero')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    if (A_list[24]-A_e_list[24]) < A_list[min_index] or (A_list[min_index]+A_e_list[min_index]) > A_list[24]:#then its consistent with the origin\n",
    "        min_index=24'''\n",
    "    '''print('at min', A_list[min_index], A_e_list[min_index])\n",
    "    print('at zero', A_list[24], A_e_list[24])\n",
    "    print('final min index', min_index)'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    if factor ==1:\n",
    "        if abs(box_list[min_index][0])>2 or abs(box_list[min_index][1])>2:\n",
    "            #then we are on the edge\n",
    "            expand=1\n",
    "        else:\n",
    "            expand=0\n",
    "    else:\n",
    "        if abs(box_list[min_index][0])>5 or abs(box_list[min_index][1])>5:\n",
    "            min_index=24\n",
    "        expand=0\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    return box_list[min_index],R_AB_list[min_index], A_list[min_index],  A_2_list[min_index],p_list, theta_list, theta_hat_list[min_index], theta_hat_e_list[min_index], expand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/Documents/Backup_My_Book/My_Passport_backup/Kinematics\n",
      "myr, view 5 0\n",
      "onto the main party\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/scipy/optimize/minpack.py:794: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/scipy/optimize/minpack.py:794: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/scipy/optimize/minpack.py:794: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/scipy/optimize/minpack.py:794: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-b5cd1df63a58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mcoords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_to_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkin_cube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mradon_python_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#was 30,30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#this means we gotta expand the grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mradon_python_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-48ea5436b13a>\u001b[0m in \u001b[0;36mradon_python_mod\u001b[0;34m(vel_field, n_p, n_theta, r_ap, factor)\u001b[0m\n\u001b[1;32m    979\u001b[0m                 \u001b[0mpopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurve_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarginalized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarginalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarginalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarginalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarginalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarginalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcov\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m                     \u001b[0mSTOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m                 \u001b[0mappend_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "os.chdir(os.path.expanduser('/Users/beckynevin/Documents/Backup_My_Book/My_Passport_backup/Kinematics/'))\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "\n",
    "view_list=[0,1,2,3,4,5,6]#1\n",
    "\n",
    "\n",
    "\n",
    "myr_list=[170,180,185,190,205,210]\n",
    "myr_list=[5,10,30,50,100,200]\n",
    "\n",
    "myr_list=[20,40,70,80,100,120,140,150,170,180,190,210,220,230,235,237,\n",
    "     240,242,245,247,250,252,255,257,262,265,270,275,280,285,\n",
    "     287,288,289,290,295,300,305]\n",
    "\n",
    "myr_list=[235,237,\n",
    "     240,242,245,247,250,252,255,257,262,265,270,275,280,285,\n",
    "     287,288,289,290,295,300,305]\n",
    "\n",
    "\n",
    "\n",
    "myr_list=[220, 225, 230, 240, 250, 260,265,275,285, 295,305,311, 315,320,\n",
    "     5,10,20,30,40,60,80,100,120,140,160]\n",
    "\n",
    "#myr_list=[185]\n",
    "#myr_list=[200,205,210]\n",
    "\n",
    "#myr_list=[5,10,20,30,40,50,60,100,200]\n",
    "#myr_list=[205,210]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "myr_list=[ 220, 225, 230, 240, 250, 260,265,275,285, 295,305,311, 315,320,\n",
    "     5,10,20,30,40,60,80,100,120,140,160]\n",
    "\n",
    "myr_list=[5,10,30,50,200]\n",
    "myr_list=[170,180,185,190,205,210]\n",
    "\n",
    "myr_list=[5,10,20,30,40,50,60,100,200]\n",
    "\n",
    "myr_list=[5,40,60,100,200,300,400,410,420,\n",
    "     600,640,700,800,840,900,940,980,1000,1020,1040,1060,1080,1100,1140,\n",
    "     1145,1150,1155,1160,1165,1168]\n",
    "\n",
    "merger=1\n",
    "\n",
    "#\n",
    "#myr_list=[   5,30,60,90,100,120,150,180,200]\n",
    "\n",
    "\n",
    "'''myr_list=[5,40,60,100,200,300,400,410,420,\n",
    "     600,640,700,800,840,900,940,980,1000,1020,1040,1060,1080,1100,1140,\n",
    "     1145,1150,1155,1160,1165,1168]'''\n",
    "\n",
    "myr_list=[20,40,70,80,100,120,140,150,170,180,190,210,220,230,235,237,\n",
    "     240,242,245,247,250,252,255,257,262,265,270,275,280,285,\n",
    "     287,288,289,290,295,300,305]\n",
    "\n",
    "myr_list=[245,247,250,252,255,257,262,265,270,275,280,285,\n",
    "     287,288,289,290,295,300,305]\n",
    "\n",
    "myr_list=[5,60,90,120,150,180,210,240,270,300,320,340,360,380,400,420,440,460,480,500]\n",
    "\n",
    "view_list=[0,1,2,3,4,5,6]\n",
    "\n",
    "#view_list=[2]\n",
    "#myr_list=[90]\n",
    "\n",
    "gas='no'\n",
    "\n",
    "adds='NONSCATTER_kin_correct_noise_conv'#stellar_kinematics_NONSCATTER_kin_correct_noi\n",
    "#run='fg3_m12_iso0.5'\n",
    "#run='fg3_m12_agnx0'\n",
    "#run='fg3_m15_iso1'\n",
    "run='fg3_m15'\n",
    "\n",
    "file1=open('LDA_kin_rerecenter_'+str(run)+'.txt','w')\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "counter=0\n",
    "z=0.03\n",
    "\n",
    "for i in range(len(myr_list)):\n",
    "    myr=myr_list[i]\n",
    "    v_offsets=[]\n",
    "    for j in range(len(view_list)):\n",
    "        im=0\n",
    "        view=view_list[j]\n",
    "        print('myr, view', myr, view)\n",
    "        if run=='fg3_m10':\n",
    "            if myr > 420:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_late/broadband_'+str(myr)+'.fits')\n",
    "            else:\n",
    "                if myr < 10:\n",
    "                    im = pyfits.open('../LAURA_Sims/q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_00'+str(myr)+'.fits')\n",
    "                else:\n",
    "                    if myr < 100:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_0'+str(myr)+'.fits')\n",
    "                    else:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_'+str(myr)+'.fits')\n",
    "        \n",
    "        \n",
    "        if run=='fg3_m13':\n",
    "            if myr > 140:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.333_fg0.3_allrx10_sunruns/hires_kin_late/broadband_'+str(myr)+'.fits')\n",
    "            else:\n",
    "                if myr < 10:\n",
    "                    im = pyfits.open('../LAURA_Sims/q0.333_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_00'+str(myr)+'.fits')\n",
    "                else:\n",
    "                    if myr < 100:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.333_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_0'+str(myr)+'.fits')\n",
    "                    else:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.333_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_'+str(myr)+'.fits')\n",
    "        \n",
    "        if run=='fg3_m12_iso0.5':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            im = pyfits.open('../LAURA_Sims/isolated_galaxies/m0.5_fg0.3/broadband_'+prefix+str(myr)+'.fits')\n",
    "            \n",
    "        \n",
    "        if run=='fg3_m12_iso1':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            im = pyfits.open('../LAURA_Sims/isolated_galaxies/m1_fg0.3/broadband_'+prefix+str(myr)+'.fits')\n",
    "            \n",
    "        if run=='fg3_m12':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            if myr < 170:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_'+prefix+str(myr)+'.fits')\n",
    "            else:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.5_fg0.3_allrx10_sunruns/hires_kin/broadband_'+prefix+str(myr)+'.fits')\n",
    "        if run=='fg3_m12_agnx0':\n",
    "            im = pyfits.open('../LAURA_Sims/q0.5_fg0.3_allrx10_sunruns/agnx0/broadband_'+str(myr)+'.fits')\n",
    "        \n",
    "        if run=='fg3_m15_iso1':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            im = pyfits.open('../LAURA_Sims/m1_fg0.3_BT0.2_allrx10_isolated_sunruns/broadband_'+prefix+str(myr)+'.fits')\n",
    "        \n",
    "        if run=='fg3_m15':\n",
    "            if myr > 300:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_late/broadband_'+str(myr)+'.fits')\n",
    "            else:\n",
    "                if myr < 10:\n",
    "                    im = pyfits.open('../LAURA_Sims/q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_00'+str(myr)+'.fits')\n",
    "                else:\n",
    "                    if myr < 100:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_0'+str(myr)+'.fits')\n",
    "                    else:\n",
    "                        im = pyfits.open('../LAURA_Sims/q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_'+str(myr)+'.fits')\n",
    "        if run=='fg1_m13':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            if myr > 140:\n",
    "                \n",
    "                if myr <360:\n",
    "                    im = pyfits.open('../LAURA_Sims/q0.333_fg0.1_allrx10_sunruns/hires_kin_late/broadband_sdss_z0.03_'+prefix+str(myr)+'.fits')\n",
    "                else:\n",
    "                    im = pyfits.open('../LAURA_Sims/q0.333_fg0.1_allrx10_sunruns/hires_kin_late/broadband_'+prefix+str(myr)+'.fits')\n",
    "            \n",
    "            else:\n",
    "                im = pyfits.open('../LAURA_Sims/q0.333_fg0.1_allrx10_sunruns/hires_kin_early_cen1/broadband_'+prefix+str(myr)+'.fits')\n",
    "            \n",
    "        if run=='fg1_m13_iso1':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            im = pyfits.open('../LAURA_Sims/isolated_galaxies/m1_fg0.1/broadband_'+prefix+str(myr)+'.fits')\n",
    "        if run=='fg1_m13_iso0.333':\n",
    "            if myr < 10:\n",
    "                prefix='00'\n",
    "            else:\n",
    "                if myr < 100:\n",
    "                    prefix='0'\n",
    "                else:\n",
    "                    prefix=''\n",
    "            im = pyfits.open('../LAURA_Sims/isolated_galaxies/m0.333_fg0.1/broadband_'+prefix+str(myr)+'.fits')\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            kin_cube=pyfits.open('stellar_kinematics_'+str(adds)+'_'+str(run)+'_'+str(myr)+'_'+str(view)+'.fits')\n",
    "            #kin_cube=pyfits.open('stellar_kinematic_maps_sunrise/stellar_kinematics_NONSCATTER_'+str(myr)+'_'+str(view)+'.fits')\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print('STELLAR velocity map not there yet', 'stellar_kinematics_'+str(adds)+'_'+str(run)+'_'+str(myr)+'_'+str(view)+'.fits')\n",
    "            continue\n",
    "        \n",
    "        dia = np.where(kin_cube[1].data != 0.0)\n",
    "        dia_pix = (dia[1].max()-dia[1].min())#this is the number of pixels\n",
    "        dia = dia_pix*0.5#because 0.5\" per spaxel\n",
    "        \n",
    "        \n",
    "        vel = ma.masked_where(kin_cube[1].data==0, kin_cube[1].data)\n",
    "        vel_e = ma.masked_where(kin_cube[2].data==0, kin_cube[2].data)\n",
    "        sig = ma.masked_where(kin_cube[3].data==0, kin_cube[3].data)\n",
    "        sig_e = ma.masked_where(kin_cube[4].data==0, kin_cube[4].data)\n",
    "        r_band = kin_cube[5].data\n",
    "        r_band = ma.masked_where(r_band>1e10, r_band)\n",
    "        \n",
    "        vel = ma.masked_where(abs(vel)>1000, vel)\n",
    "        vel_e = ma.masked_where(abs(vel)>1000, vel_e)\n",
    "        \n",
    "        \n",
    "        img_params=extract_GALFIT_parameters(view, myr, im, run)\n",
    "        #return PA_img, size_a, arcs_totes, inc, pixelscale, r_e\n",
    "        if img_params[0]==0:\n",
    "            #this means the GALFIT file doesn't exist\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            #I have found the PA from GALFIT to be better than the PA from statmorph \n",
    "            #which is commented out below\n",
    "            PA_imag=img_params[0]\n",
    "        except TypeError:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        epsilon = 1-img_params[1]\n",
    "        r_e = img_params[2]\n",
    "        \n",
    "        #print('deltapos', deltapos)\n",
    "        #continue\n",
    "        \n",
    "        #epsilon = float(kin_cube[0].header['ellip']), again the epsilon from GALFIT is better\n",
    "        #r_e = float(kin_cube[0].header['REFF'])\n",
    "        #PA_img = float(kin_cube[0].header['PA_img']), again, the PA from GALFIT seems to be better\n",
    "        \n",
    "        '''axial ratio (q) = b/a = semi-minor/semi-major\n",
    "        ellipticity (ε) = 1 – q'''\n",
    "        \n",
    "        \n",
    "        \n",
    "        #from the r-band image you need to run statmorph and get both the ellipticity and the r-band effective radius\n",
    "        #we already measured this from the r-band image in the kinematic program so I'd like to extract those two \n",
    "        #parameters from the header of the stellar_kinematics file\n",
    "        \n",
    "        \n",
    "        \n",
    "        size=np.shape(vel)[0]\n",
    "        coords=map_to_coords(kin_cube, size)\n",
    "        \n",
    "        rad = radon_python_mod(vel, 30, 30, r_e, 1)#was 30,30\n",
    "        if rad[8]==1:#this means we gotta expand the grid\n",
    "            rad = radon_python_mod(vel, 30, 30, r_e, 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        input_kinemetry(run, myr, view, coords[0], coords[1], coords[2], coords[3], coords[4], coords[5] , size/2-rad[0][0], size/2-rad[0][1], adds)\n",
    "        \n",
    "        continue\n",
    "        \n",
    "        \n",
    "        deltapos = compare_centers(r_band, sig, size/2-rad[0][0], size/2-rad[0][1], z)\n",
    "        \n",
    "        \n",
    "        ang_mom = angular_momentum(vel, sig, r_band, r_e)\n",
    "        \n",
    "        \n",
    "        myr_actual = im['SFRHIST'].header['SNAPTIME']/10**9\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        out_kin=read_kin_maps(r_band, run, myr, view, dia, PA_imag, size, adds, vel, rad[0])\n",
    "        \n",
    "        if out_kin==0:\n",
    "            continue\n",
    "        \n",
    "        if counter==0:\n",
    "            file1.write('Counter'+'\\t'+'Image'+'\\t'+'class label'+'\\t'+'Myr'+'\\t'+'Viewpoint'+'\\t'+'Delta PA'+'\\t'+'v_asym'+'\\t'+'s_asym'+'\\t'+'resids'+'\\t'+'lambda_r'+'\\t'+'epsilon'+'\\t'+'A'+'\\t'+'A_2'+'\\t'+'deltapos'+'\\t'+'deltapos2'+'\\n')#+'i'+'\\t'+'fiber'+'\\n')#was str(np.shape(vel_dist)[1]-1-j)\n",
    "        try:\n",
    "            make_table(counter,run, merger, myr_actual, view, out_kin[0], out_kin[1], out_kin[2], out_kin[4],i, j, ang_mom, epsilon, rad[2],  rad[3], deltapos[0], deltapos[1])#, inclination, fiber[0])\n",
    "        except TypeError:\n",
    "            continue\n",
    "        counter+=1\n",
    "        \n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        \n",
    "        \n",
    "        continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "file1.close()\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
